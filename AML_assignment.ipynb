{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xyv_FbtOcuqG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from numpy.random import seed\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm as gbm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the Cover Type dataset while dropping rows with NaN\n",
    "def load_cover_type():\n",
    "    cov_train_df = pd.read_csv('covtype_train.csv')\n",
    "    cov_train_df = cov_train_df[cov_train_df['Cover_Type'].notna()]\n",
    "    \n",
    "    X_train_cov = cov_train_df.drop(['Cover_Type'], axis=1)\n",
    "    y_train_cov = cov_train_df['Cover_Type']\n",
    "\n",
    "    return cov_train_df, X_train_cov, y_train_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the HELOC dataset while dropping rows with NaN and negative values\n",
    "def load_heloc():\n",
    "    heloc_train_df = pd.read_csv('heloc_train.csv')\n",
    "\n",
    "    heloc_train_df[heloc_train_df.drop('RiskPerformance', axis=1) <0 ] = np.nan\n",
    "    heloc_train_df = heloc_train_df.dropna()\n",
    "    \n",
    "    heloc_train_df = heloc_train_df[heloc_train_df['RiskPerformance'].notna()]\n",
    "    \n",
    "    X_heloc = heloc_train_df.drop('RiskPerformance', axis=1)\n",
    "    y_heloc = heloc_train_df['RiskPerformance']\n",
    "\n",
    "    return heloc_train_df, X_heloc, y_heloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the HIGGS dataset while dropping rows with NaN values, -999 values, correlated columns: \n",
    "    #PRI_jet_all_pt\n",
    "    #PRI_met_sumet\n",
    "    #DER_mass_vis\n",
    "#as well as the Weight column\n",
    "def load_higgs(corr=True):\n",
    "    higgs_train_df = pd.read_csv('higgs_train.csv')\n",
    "    higgs_train_df = higgs_train_df[higgs_train_df['Label'].notna()]\n",
    "    higgs_train_df = higgs_train_df.drop('EventId', axis=1)\n",
    "    higgs_train_df = higgs_train_df.replace(-999.0, np.NaN)\n",
    "    higgs_train_df = higgs_train_df.dropna()\n",
    "\n",
    "    if corr:\n",
    "        higgs_train_df = higgs_train_df.drop(['PRI_jet_all_pt', \"PRI_met_sumet\", 'DER_mass_vis'], axis=1)\n",
    "        \n",
    "    X_higgs = higgs_train_df.drop('Label', axis=1)\n",
    "    X_higgs = X_higgs.drop('Weight', axis=1)\n",
    "    y_higgs = higgs_train_df['Label']\n",
    "\n",
    "    return higgs_train_df, X_higgs, y_higgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adds synthetic data to the Cover Type dataset to compensate for underepresented classes using SMOTE\n",
    "def resample_cover_type(X_train_cov, y_train_cov):\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train_cov, y_train_cov)\n",
    "\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encodes the labels of each dataset and splits them into a training and test subset\n",
    "def le_split(X, y, t_size=0.3):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = t_size, random_state=42)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.fit_transform(y_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs grid search to find optimal hyperparamteres for a given model\n",
    "def train_model(model, X, y, grid=False, params={} ):\n",
    "    if grid:\n",
    "        grid_search = GridSearchCV(model, params, scoring=\"accuracy\", n_jobs=-1, cv=10, verbose = 6)\n",
    "        results = grid_search.fit(X, y)\n",
    "        model = results.best_estimator_\n",
    "        print(results.best_params_)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates a given model on the test subset\n",
    "def evaluate_model(model, X, y):\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    acc = accuracy_score(y, predictions)\n",
    "    \n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y, predictions))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run the TabNet model for a given dataset\n",
    "def run_tabnet(X, y):\n",
    "\n",
    "    X= X.to_numpy()\n",
    "    y= y.to_numpy()\n",
    "\n",
    "    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    CV_score_array    = []\n",
    "\n",
    "\n",
    "    counter = 0\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        if counter == 1:\n",
    "            break\n",
    "        X_train, X_valid = X[train_index], X[test_index]\n",
    "        y_train, y_valid = y[train_index], y[test_index]\n",
    "\n",
    "        tb_cls = TabNetClassifier(optimizer_fn=torch.optim.Adam,\n",
    "                       optimizer_params=dict(lr=1e-3),\n",
    "                       scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                        mask_type = 'entmax', \n",
    "                        device_name = 'cpu'\n",
    "                       )\n",
    "        \n",
    "        tb_cls.fit(X_train,y_train,\n",
    "               eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "               eval_name=['train', 'valid'],\n",
    "               eval_metric=['accuracy'],\n",
    "               max_epochs=1000 , patience=10,\n",
    "               batch_size=28, drop_last=True)            \n",
    "        CV_score_array.append(tb_cls.best_cost)\n",
    "        counter += 1\n",
    "\n",
    "    print(\"Total Accuracy: \", sum(CV_score_array) / len(CV_score_array))\n",
    "\n",
    "    return tb_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads the final submissions datasets\n",
    "def load_tests():\n",
    "    y_final_cov = pd.read_csv('covtype_test.csv')\n",
    "    y_final_heloc = pd.read_csv('heloc_test.csv')\n",
    "    y_final_higgs = pd.read_csv('higgs_test.csv').drop(['EventId', 'Weight', 'PRI_jet_all_pt', \"PRI_met_sumet\", 'DER_mass_vis' ], axis=1)\n",
    "\n",
    "    return y_final_cov, y_final_heloc, y_final_higgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the concatenated final predictions as well as the predictions for each model separately\n",
    "def get_final_predictions(model_cov, model_heloc, model_higgs, isTab=False):\n",
    "    y_final_cov, y_final_heloc, y_final_higgs = load_tests()\n",
    "\n",
    "    if isTab:\n",
    "        final_preds_cov = model_cov.predict(y_final_cov.to_numpy())\n",
    "        final_preds_heloc = model_heloc.predict(y_final_heloc.to_numpy())\n",
    "        final_preds_higgs = model_higgs.predict(y_final_higgs.to_numpy())\n",
    "    else:\n",
    "        final_preds_cov = model_cov.predict(y_final_cov)+1\n",
    "        final_preds_heloc = model_heloc.predict(y_final_heloc)\n",
    "        final_preds_higgs = model_higgs.predict(y_final_higgs)\n",
    "\n",
    "    final_preds = np.concatenate((final_preds_cov, final_preds_heloc, final_preds_higgs))\n",
    "\n",
    "    return final_preds, final_preds_cov, final_preds_heloc, final_preds_higgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cover Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_train_df, X_cov, y_cov = load_cover_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    28248\n",
       "1    21297\n",
       "3     3607\n",
       "7     2052\n",
       "6     1706\n",
       "5      932\n",
       "4      259\n",
       "Name: Cover_Type, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_train_df['Cover_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = resample_cover_type(X_cov, y_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cover_Type\n",
       "1             28248\n",
       "2             28248\n",
       "3             28248\n",
       "4             28248\n",
       "5             28248\n",
       "6             28248\n",
       "7             28248\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_resampled).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cov, X_test_cov, y_train_cov, y_test_cov = le_split(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Heloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "heloc_train_df, X_heloc, y_heloc = load_heloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_heloc, X_test_heloc, y_train_heloc, y_test_heloc = le_split(X_heloc, y_heloc, t_size =0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Higgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "higgs_train_df, X_higgs, y_higgs = load_higgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnp\\AppData\\Local\\Temp\\ipykernel_13256\\3153411704.py:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  corr = higgs_train_df.corr()\n",
      "C:\\Users\\johnp\\AppData\\Local\\Temp\\ipykernel_13256\\3153411704.py:3: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
      "  corr.style.background_gradient(cmap='coolwarm').set_precision(2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b3497_row0_col0, #T_b3497_row1_col1, #T_b3497_row2_col2, #T_b3497_row3_col3, #T_b3497_row4_col4, #T_b3497_row5_col5, #T_b3497_row6_col6, #T_b3497_row7_col7, #T_b3497_row8_col8, #T_b3497_row9_col9, #T_b3497_row10_col10, #T_b3497_row11_col11, #T_b3497_row12_col12, #T_b3497_row13_col13, #T_b3497_row14_col14, #T_b3497_row15_col15, #T_b3497_row16_col16, #T_b3497_row17_col17, #T_b3497_row18_col18, #T_b3497_row19_col19, #T_b3497_row20_col20, #T_b3497_row21_col21, #T_b3497_row22_col22, #T_b3497_row23_col23, #T_b3497_row24_col24, #T_b3497_row25_col25, #T_b3497_row26_col26, #T_b3497_row27_col27 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row0_col1, #T_b3497_row2_col3, #T_b3497_row12_col5, #T_b3497_row14_col4, #T_b3497_row18_col24, #T_b3497_row23_col4, #T_b3497_row24_col7 {\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row0_col2, #T_b3497_row9_col3, #T_b3497_row9_col27, #T_b3497_row15_col3 {\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row0_col3, #T_b3497_row0_col12, #T_b3497_row20_col21 {\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row0_col4, #T_b3497_row3_col6, #T_b3497_row5_col27 {\n",
       "  background-color: #c6d6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row0_col5, #T_b3497_row4_col8, #T_b3497_row7_col24, #T_b3497_row8_col5, #T_b3497_row10_col21 {\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row0_col6 {\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row0_col7, #T_b3497_row1_col24, #T_b3497_row6_col14, #T_b3497_row11_col24, #T_b3497_row21_col1, #T_b3497_row25_col16 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row0_col8, #T_b3497_row0_col9 {\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row0_col10, #T_b3497_row0_col19, #T_b3497_row0_col23, #T_b3497_row2_col23, #T_b3497_row6_col19, #T_b3497_row6_col23, #T_b3497_row7_col19, #T_b3497_row8_col17, #T_b3497_row8_col23, #T_b3497_row9_col17, #T_b3497_row11_col17, #T_b3497_row11_col19, #T_b3497_row11_col23, #T_b3497_row12_col17, #T_b3497_row12_col19, #T_b3497_row13_col23, #T_b3497_row15_col17, #T_b3497_row15_col23, #T_b3497_row16_col19, #T_b3497_row16_col23, #T_b3497_row16_col27, #T_b3497_row18_col17, #T_b3497_row18_col23, #T_b3497_row20_col17, #T_b3497_row20_col19, #T_b3497_row20_col23, #T_b3497_row24_col17, #T_b3497_row24_col23, #T_b3497_row26_col10, #T_b3497_row27_col17, #T_b3497_row27_col23 {\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row0_col11, #T_b3497_row15_col11, #T_b3497_row20_col6 {\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row0_col13, #T_b3497_row3_col13, #T_b3497_row3_col16, #T_b3497_row3_col27, #T_b3497_row4_col13, #T_b3497_row8_col16, #T_b3497_row10_col13, #T_b3497_row12_col13, #T_b3497_row12_col16, #T_b3497_row14_col13, #T_b3497_row15_col13, #T_b3497_row15_col16, #T_b3497_row18_col13, #T_b3497_row18_col16, #T_b3497_row21_col16, #T_b3497_row23_col16, #T_b3497_row24_col13 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row0_col14, #T_b3497_row1_col14, #T_b3497_row13_col14 {\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row0_col15, #T_b3497_row24_col11 {\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row0_col16, #T_b3497_row4_col0, #T_b3497_row5_col13, #T_b3497_row17_col13 {\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row0_col17, #T_b3497_row1_col23, #T_b3497_row2_col19, #T_b3497_row3_col23, #T_b3497_row4_col23, #T_b3497_row5_col17, #T_b3497_row6_col17, #T_b3497_row7_col23, #T_b3497_row8_col1, #T_b3497_row8_col19, #T_b3497_row9_col19, #T_b3497_row10_col19, #T_b3497_row10_col23, #T_b3497_row12_col23, #T_b3497_row13_col17, #T_b3497_row13_col19, #T_b3497_row15_col19, #T_b3497_row16_col10, #T_b3497_row16_col17, #T_b3497_row17_col10, #T_b3497_row18_col19, #T_b3497_row19_col1, #T_b3497_row21_col19, #T_b3497_row21_col23, #T_b3497_row24_col15, #T_b3497_row24_col19, #T_b3497_row25_col23 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row0_col18, #T_b3497_row0_col27, #T_b3497_row13_col11, #T_b3497_row14_col11, #T_b3497_row16_col11, #T_b3497_row17_col11, #T_b3497_row18_col11, #T_b3497_row19_col11, #T_b3497_row20_col9, #T_b3497_row21_col11 {\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row0_col20, #T_b3497_row23_col7 {\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row0_col21, #T_b3497_row9_col11, #T_b3497_row14_col9, #T_b3497_row16_col9, #T_b3497_row16_col21, #T_b3497_row18_col9, #T_b3497_row23_col12, #T_b3497_row25_col9, #T_b3497_row25_col21, #T_b3497_row26_col9 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row0_col22, #T_b3497_row1_col22, #T_b3497_row1_col25, #T_b3497_row5_col24, #T_b3497_row6_col22, #T_b3497_row9_col22, #T_b3497_row9_col25, #T_b3497_row10_col22, #T_b3497_row11_col22, #T_b3497_row11_col25, #T_b3497_row15_col22, #T_b3497_row20_col25, #T_b3497_row23_col25, #T_b3497_row26_col22, #T_b3497_row26_col25, #T_b3497_row27_col0, #T_b3497_row27_col11 {\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row0_col24, #T_b3497_row4_col14, #T_b3497_row5_col14, #T_b3497_row9_col14, #T_b3497_row15_col14, #T_b3497_row20_col15, #T_b3497_row24_col14, #T_b3497_row25_col14, #T_b3497_row26_col24, #T_b3497_row27_col14 {\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row0_col25, #T_b3497_row6_col25, #T_b3497_row12_col0, #T_b3497_row14_col22, #T_b3497_row17_col22, #T_b3497_row19_col22, #T_b3497_row22_col13 {\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row0_col26, #T_b3497_row3_col26, #T_b3497_row4_col26, #T_b3497_row5_col26, #T_b3497_row7_col26, #T_b3497_row11_col26, #T_b3497_row13_col26, #T_b3497_row15_col26, #T_b3497_row16_col26, #T_b3497_row18_col0, #T_b3497_row21_col26, #T_b3497_row22_col26 {\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row1_col0, #T_b3497_row20_col11, #T_b3497_row27_col4 {\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row1_col2, #T_b3497_row3_col21, #T_b3497_row5_col18, #T_b3497_row11_col18, #T_b3497_row17_col18, #T_b3497_row20_col1, #T_b3497_row22_col18, #T_b3497_row25_col18, #T_b3497_row26_col18 {\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row1_col3, #T_b3497_row2_col9, #T_b3497_row5_col2 {\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row1_col4, #T_b3497_row1_col15, #T_b3497_row7_col9, #T_b3497_row7_col12, #T_b3497_row8_col10, #T_b3497_row13_col22 {\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row1_col5, #T_b3497_row2_col10 {\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row1_col6, #T_b3497_row10_col4, #T_b3497_row27_col1 {\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row1_col7, #T_b3497_row2_col17, #T_b3497_row3_col8, #T_b3497_row3_col17, #T_b3497_row4_col19, #T_b3497_row5_col23, #T_b3497_row7_col17, #T_b3497_row9_col23, #T_b3497_row15_col7, #T_b3497_row21_col17, #T_b3497_row27_col19 {\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row1_col8, #T_b3497_row12_col10, #T_b3497_row13_col8 {\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row1_col9, #T_b3497_row1_col27 {\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row1_col10, #T_b3497_row2_col6, #T_b3497_row2_col13, #T_b3497_row2_col16, #T_b3497_row3_col5, #T_b3497_row3_col7, #T_b3497_row3_col20, #T_b3497_row5_col3, #T_b3497_row5_col4, #T_b3497_row5_col11, #T_b3497_row6_col2, #T_b3497_row6_col8, #T_b3497_row6_col15, #T_b3497_row6_col18, #T_b3497_row6_col21, #T_b3497_row6_col24, #T_b3497_row8_col13, #T_b3497_row9_col12, #T_b3497_row10_col1, #T_b3497_row10_col16, #T_b3497_row10_col27, #T_b3497_row11_col0, #T_b3497_row12_col9, #T_b3497_row17_col23, #T_b3497_row17_col26, #T_b3497_row19_col23, #T_b3497_row21_col13, #T_b3497_row22_col25, #T_b3497_row23_col14, #T_b3497_row23_col17, #T_b3497_row23_col19, #T_b3497_row25_col22 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row1_col11, #T_b3497_row4_col9, #T_b3497_row13_col18, #T_b3497_row16_col18 {\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row1_col12, #T_b3497_row2_col20, #T_b3497_row7_col11 {\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row1_col13, #T_b3497_row4_col27, #T_b3497_row5_col16, #T_b3497_row6_col13, #T_b3497_row9_col16, #T_b3497_row17_col16, #T_b3497_row19_col13, #T_b3497_row19_col26, #T_b3497_row20_col13, #T_b3497_row26_col16, #T_b3497_row27_col13 {\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row1_col16, #T_b3497_row3_col0, #T_b3497_row4_col16, #T_b3497_row7_col13, #T_b3497_row7_col16, #T_b3497_row9_col13, #T_b3497_row11_col13, #T_b3497_row11_col16, #T_b3497_row14_col16, #T_b3497_row19_col16, #T_b3497_row20_col16, #T_b3497_row23_col13, #T_b3497_row24_col16, #T_b3497_row26_col13 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row1_col17, #T_b3497_row5_col19, #T_b3497_row10_col6, #T_b3497_row13_col10, #T_b3497_row14_col1, #T_b3497_row20_col10, #T_b3497_row22_col17, #T_b3497_row22_col19 {\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row1_col18, #T_b3497_row1_col21, #T_b3497_row14_col10, #T_b3497_row16_col1, #T_b3497_row18_col20, #T_b3497_row22_col1, #T_b3497_row24_col6, #T_b3497_row25_col1, #T_b3497_row25_col10 {\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row1_col19, #T_b3497_row3_col19, #T_b3497_row4_col17, #T_b3497_row9_col24, #T_b3497_row10_col17, #T_b3497_row13_col27, #T_b3497_row22_col23, #T_b3497_row25_col17, #T_b3497_row25_col19, #T_b3497_row26_col27 {\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row1_col20, #T_b3497_row3_col25, #T_b3497_row4_col25, #T_b3497_row9_col7, #T_b3497_row21_col25, #T_b3497_row22_col24, #T_b3497_row23_col24, #T_b3497_row25_col24, #T_b3497_row27_col12 {\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row1_col26, #T_b3497_row4_col15, #T_b3497_row8_col0, #T_b3497_row9_col26, #T_b3497_row18_col27, #T_b3497_row25_col26 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row2_col0, #T_b3497_row5_col0, #T_b3497_row6_col20 {\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row2_col1, #T_b3497_row2_col26, #T_b3497_row3_col24, #T_b3497_row8_col26, #T_b3497_row8_col27, #T_b3497_row12_col26, #T_b3497_row18_col26, #T_b3497_row20_col26 {\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row2_col4, #T_b3497_row6_col0 {\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row2_col5, #T_b3497_row15_col4, #T_b3497_row18_col10 {\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row2_col7, #T_b3497_row15_col0, #T_b3497_row18_col7 {\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row2_col8, #T_b3497_row11_col3 {\n",
       "  background-color: #ec8165;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row2_col11, #T_b3497_row14_col19, #T_b3497_row15_col18, #T_b3497_row16_col22, #T_b3497_row21_col9 {\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row2_col12 {\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row2_col14, #T_b3497_row7_col14, #T_b3497_row7_col22, #T_b3497_row8_col14, #T_b3497_row9_col10, #T_b3497_row13_col24, #T_b3497_row17_col25, #T_b3497_row18_col14, #T_b3497_row19_col25, #T_b3497_row20_col27, #T_b3497_row21_col14, #T_b3497_row22_col14, #T_b3497_row23_col22 {\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row2_col15, #T_b3497_row12_col3, #T_b3497_row19_col5 {\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row2_col18 {\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row2_col21, #T_b3497_row15_col9 {\n",
       "  background-color: #e8765c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row2_col22, #T_b3497_row2_col25, #T_b3497_row3_col22, #T_b3497_row4_col22, #T_b3497_row5_col22, #T_b3497_row5_col25, #T_b3497_row7_col15, #T_b3497_row7_col25, #T_b3497_row8_col22, #T_b3497_row8_col25, #T_b3497_row9_col20, #T_b3497_row10_col25, #T_b3497_row12_col1, #T_b3497_row12_col7, #T_b3497_row12_col22, #T_b3497_row12_col25, #T_b3497_row14_col17, #T_b3497_row14_col24, #T_b3497_row14_col25, #T_b3497_row15_col25, #T_b3497_row16_col24, #T_b3497_row17_col24, #T_b3497_row18_col22, #T_b3497_row18_col25, #T_b3497_row19_col24, #T_b3497_row20_col22, #T_b3497_row21_col22, #T_b3497_row24_col22, #T_b3497_row24_col25, #T_b3497_row26_col23, #T_b3497_row27_col18, #T_b3497_row27_col22, #T_b3497_row27_col25 {\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row2_col24 {\n",
       "  background-color: #d9dce1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row2_col27, #T_b3497_row14_col23, #T_b3497_row23_col26 {\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row3_col1, #T_b3497_row4_col1, #T_b3497_row11_col5, #T_b3497_row13_col7, #T_b3497_row13_col20, #T_b3497_row16_col7, #T_b3497_row16_col20, #T_b3497_row17_col20, #T_b3497_row18_col6, #T_b3497_row19_col7, #T_b3497_row19_col20, #T_b3497_row22_col20, #T_b3497_row23_col20, #T_b3497_row25_col20, #T_b3497_row26_col7 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row3_col2, #T_b3497_row9_col21, #T_b3497_row20_col18 {\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row3_col4 {\n",
       "  background-color: #da5a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row3_col9, #T_b3497_row5_col7, #T_b3497_row10_col24 {\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row3_col10, #T_b3497_row3_col12, #T_b3497_row4_col6, #T_b3497_row5_col8, #T_b3497_row7_col1, #T_b3497_row11_col10, #T_b3497_row11_col21, #T_b3497_row15_col6, #T_b3497_row16_col25, #T_b3497_row19_col21, #T_b3497_row22_col21, #T_b3497_row23_col21, #T_b3497_row26_col21 {\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row3_col11 {\n",
       "  background-color: #f29072;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row3_col14, #T_b3497_row10_col14, #T_b3497_row11_col14, #T_b3497_row12_col14, #T_b3497_row12_col20, #T_b3497_row16_col14, #T_b3497_row20_col14 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row3_col15, #T_b3497_row11_col20, #T_b3497_row11_col27, #T_b3497_row19_col0, #T_b3497_row23_col0, #T_b3497_row26_col0 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row3_col18, #T_b3497_row10_col9, #T_b3497_row17_col1 {\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row4_col2, #T_b3497_row4_col21, #T_b3497_row18_col4 {\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row4_col3 {\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row4_col5, #T_b3497_row17_col0, #T_b3497_row20_col0, #T_b3497_row22_col0 {\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row4_col7 {\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row4_col10, #T_b3497_row5_col9, #T_b3497_row7_col3, #T_b3497_row20_col3, #T_b3497_row22_col11, #T_b3497_row23_col11, #T_b3497_row25_col11, #T_b3497_row26_col11 {\n",
       "  background-color: #b3cdfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row4_col11 {\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row4_col12, #T_b3497_row4_col18, #T_b3497_row7_col4, #T_b3497_row11_col6, #T_b3497_row12_col18, #T_b3497_row13_col2, #T_b3497_row16_col2, #T_b3497_row24_col20 {\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row4_col20, #T_b3497_row12_col27 {\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row4_col24, #T_b3497_row6_col9, #T_b3497_row12_col11, #T_b3497_row21_col15 {\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row5_col1, #T_b3497_row11_col12, #T_b3497_row20_col12 {\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row5_col6, #T_b3497_row6_col27, #T_b3497_row8_col9, #T_b3497_row10_col8, #T_b3497_row14_col2, #T_b3497_row16_col6, #T_b3497_row17_col6, #T_b3497_row19_col2, #T_b3497_row22_col6, #T_b3497_row24_col3, #T_b3497_row25_col6, #T_b3497_row26_col6 {\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row5_col10 {\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row5_col12, #T_b3497_row9_col18, #T_b3497_row19_col18, #T_b3497_row21_col20, #T_b3497_row23_col18 {\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row5_col15, #T_b3497_row14_col20, #T_b3497_row17_col7, #T_b3497_row24_col27, #T_b3497_row25_col7, #T_b3497_row26_col19, #T_b3497_row26_col20 {\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row5_col20, #T_b3497_row13_col1, #T_b3497_row19_col10, #T_b3497_row22_col10, #T_b3497_row23_col1, #T_b3497_row23_col10, #T_b3497_row26_col1 {\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row5_col21, #T_b3497_row12_col24, #T_b3497_row13_col12, #T_b3497_row14_col8, #T_b3497_row16_col12, #T_b3497_row19_col8, #T_b3497_row21_col7, #T_b3497_row23_col9, #T_b3497_row24_col10, #T_b3497_row26_col12 {\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row6_col1, #T_b3497_row8_col3, #T_b3497_row9_col8, #T_b3497_row17_col2, #T_b3497_row25_col2, #T_b3497_row26_col2 {\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row6_col3 {\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row6_col4, #T_b3497_row10_col12 {\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row6_col5, #T_b3497_row13_col5, #T_b3497_row14_col5, #T_b3497_row15_col1, #T_b3497_row16_col5, #T_b3497_row17_col5, #T_b3497_row23_col3, #T_b3497_row24_col5, #T_b3497_row26_col3 {\n",
       "  background-color: #d2dbe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row6_col7 {\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row6_col10 {\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row6_col11, #T_b3497_row24_col9 {\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row6_col12 {\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row6_col16, #T_b3497_row10_col0 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row6_col26, #T_b3497_row8_col6, #T_b3497_row27_col7, #T_b3497_row27_col26 {\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row7_col0 {\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row7_col2, #T_b3497_row12_col4, #T_b3497_row17_col19, #T_b3497_row19_col17 {\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row7_col5, #T_b3497_row20_col5 {\n",
       "  background-color: #e3d9d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row7_col6, #T_b3497_row8_col11, #T_b3497_row14_col21 {\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row7_col8 {\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row7_col10, #T_b3497_row15_col20, #T_b3497_row22_col16 {\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row7_col18, #T_b3497_row10_col5, #T_b3497_row13_col6, #T_b3497_row19_col6, #T_b3497_row22_col2, #T_b3497_row23_col2, #T_b3497_row23_col6 {\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row7_col20, #T_b3497_row20_col7 {\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row7_col21, #T_b3497_row9_col2, #T_b3497_row9_col6, #T_b3497_row13_col3, #T_b3497_row14_col3, #T_b3497_row17_col3, #T_b3497_row18_col5, #T_b3497_row22_col3, #T_b3497_row22_col5, #T_b3497_row25_col5, #T_b3497_row26_col5 {\n",
       "  background-color: #d1dae9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row7_col27, #T_b3497_row12_col6, #T_b3497_row18_col1, #T_b3497_row18_col15 {\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row8_col2 {\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row8_col4, #T_b3497_row12_col21 {\n",
       "  background-color: #ebd3c6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row8_col7, #T_b3497_row8_col15, #T_b3497_row24_col18 {\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row8_col12 {\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row8_col18, #T_b3497_row15_col2 {\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row8_col20, #T_b3497_row9_col5 {\n",
       "  background-color: #dadce0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row8_col21 {\n",
       "  background-color: #d0473d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row8_col24 {\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row9_col0, #T_b3497_row10_col26, #T_b3497_row14_col15, #T_b3497_row17_col15, #T_b3497_row19_col15, #T_b3497_row21_col6, #T_b3497_row22_col15, #T_b3497_row24_col26, #T_b3497_row25_col15, #T_b3497_row26_col15 {\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row9_col1, #T_b3497_row16_col3, #T_b3497_row19_col3, #T_b3497_row23_col5, #T_b3497_row25_col3 {\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row9_col4, #T_b3497_row11_col2, #T_b3497_row21_col10 {\n",
       "  background-color: #c3d5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row9_col15 {\n",
       "  background-color: #f18d6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row10_col2, #T_b3497_row24_col2 {\n",
       "  background-color: #f3c7b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row10_col3 {\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row10_col7 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row10_col11, #T_b3497_row20_col24 {\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row10_col15, #T_b3497_row11_col15 {\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row10_col18 {\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row10_col20, #T_b3497_row22_col7 {\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row11_col1 {\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row11_col4 {\n",
       "  background-color: #f7aa8c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row11_col7, #T_b3497_row14_col0, #T_b3497_row14_col26, #T_b3497_row27_col10 {\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row11_col8, #T_b3497_row11_col9, #T_b3497_row27_col2 {\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row12_col2 {\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row12_col8 {\n",
       "  background-color: #f5c2aa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row12_col15, #T_b3497_row16_col15, #T_b3497_row23_col15, #T_b3497_row27_col20, #T_b3497_row27_col24 {\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row13_col0, #T_b3497_row21_col0 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row13_col4, #T_b3497_row16_col4, #T_b3497_row18_col3, #T_b3497_row19_col4, #T_b3497_row21_col3, #T_b3497_row22_col4, #T_b3497_row25_col4, #T_b3497_row26_col4 {\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row13_col9, #T_b3497_row13_col21, #T_b3497_row13_col25, #T_b3497_row14_col12, #T_b3497_row15_col12, #T_b3497_row15_col24, #T_b3497_row15_col27, #T_b3497_row17_col9, #T_b3497_row17_col12, #T_b3497_row17_col21, #T_b3497_row19_col9, #T_b3497_row19_col12, #T_b3497_row19_col14, #T_b3497_row22_col9, #T_b3497_row22_col12, #T_b3497_row25_col12 {\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row13_col15, #T_b3497_row21_col27 {\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row13_col16, #T_b3497_row16_col13 {\n",
       "  background-color: #f2c9b4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row14_col6, #T_b3497_row20_col4 {\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row14_col7 {\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row14_col18, #T_b3497_row27_col3 {\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row14_col27, #T_b3497_row17_col27, #T_b3497_row22_col27, #T_b3497_row23_col27, #T_b3497_row24_col1, #T_b3497_row25_col27 {\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row15_col5 {\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row15_col8 {\n",
       "  background-color: #f4c6af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row15_col10, #T_b3497_row19_col27 {\n",
       "  background-color: #84a7fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row15_col21 {\n",
       "  background-color: #e4d9d2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row16_col0, #T_b3497_row25_col0 {\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row16_col8, #T_b3497_row17_col8, #T_b3497_row25_col8, #T_b3497_row26_col8 {\n",
       "  background-color: #a1c0ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row17_col4 {\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row17_col14, #T_b3497_row26_col17 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row18_col2 {\n",
       "  background-color: #df634e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row18_col8, #T_b3497_row21_col24 {\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row18_col12, #T_b3497_row24_col12 {\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row18_col21 {\n",
       "  background-color: #f5a081;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row20_col2, #T_b3497_row27_col9 {\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row20_col8 {\n",
       "  background-color: #f0cdbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row21_col2 {\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row21_col4, #T_b3497_row27_col5 {\n",
       "  background-color: #f1cdba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row21_col5 {\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row21_col8 {\n",
       "  background-color: #d1493f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row21_col12 {\n",
       "  background-color: #ead5c9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row21_col18 {\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row22_col8, #T_b3497_row23_col8 {\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row24_col0, #T_b3497_row27_col16 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row24_col4 {\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row24_col8 {\n",
       "  background-color: #eb7d62;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row24_col21 {\n",
       "  background-color: #f7a98b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row25_col13 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row26_col14 {\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row27_col6 {\n",
       "  background-color: #e6d7cf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b3497_row27_col8, #T_b3497_row27_col15 {\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b3497_row27_col21 {\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b3497\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b3497_level0_col0\" class=\"col_heading level0 col0\" >DER_mass_MMC</th>\n",
       "      <th id=\"T_b3497_level0_col1\" class=\"col_heading level0 col1\" >DER_mass_transverse_met_lep</th>\n",
       "      <th id=\"T_b3497_level0_col2\" class=\"col_heading level0 col2\" >DER_pt_h</th>\n",
       "      <th id=\"T_b3497_level0_col3\" class=\"col_heading level0 col3\" >DER_deltaeta_jet_jet</th>\n",
       "      <th id=\"T_b3497_level0_col4\" class=\"col_heading level0 col4\" >DER_mass_jet_jet</th>\n",
       "      <th id=\"T_b3497_level0_col5\" class=\"col_heading level0 col5\" >DER_prodeta_jet_jet</th>\n",
       "      <th id=\"T_b3497_level0_col6\" class=\"col_heading level0 col6\" >DER_deltar_tau_lep</th>\n",
       "      <th id=\"T_b3497_level0_col7\" class=\"col_heading level0 col7\" >DER_pt_tot</th>\n",
       "      <th id=\"T_b3497_level0_col8\" class=\"col_heading level0 col8\" >DER_sum_pt</th>\n",
       "      <th id=\"T_b3497_level0_col9\" class=\"col_heading level0 col9\" >DER_pt_ratio_lep_tau</th>\n",
       "      <th id=\"T_b3497_level0_col10\" class=\"col_heading level0 col10\" >DER_met_phi_centrality</th>\n",
       "      <th id=\"T_b3497_level0_col11\" class=\"col_heading level0 col11\" >DER_lep_eta_centrality</th>\n",
       "      <th id=\"T_b3497_level0_col12\" class=\"col_heading level0 col12\" >PRI_tau_pt</th>\n",
       "      <th id=\"T_b3497_level0_col13\" class=\"col_heading level0 col13\" >PRI_tau_eta</th>\n",
       "      <th id=\"T_b3497_level0_col14\" class=\"col_heading level0 col14\" >PRI_tau_phi</th>\n",
       "      <th id=\"T_b3497_level0_col15\" class=\"col_heading level0 col15\" >PRI_lep_pt</th>\n",
       "      <th id=\"T_b3497_level0_col16\" class=\"col_heading level0 col16\" >PRI_lep_eta</th>\n",
       "      <th id=\"T_b3497_level0_col17\" class=\"col_heading level0 col17\" >PRI_lep_phi</th>\n",
       "      <th id=\"T_b3497_level0_col18\" class=\"col_heading level0 col18\" >PRI_met</th>\n",
       "      <th id=\"T_b3497_level0_col19\" class=\"col_heading level0 col19\" >PRI_met_phi</th>\n",
       "      <th id=\"T_b3497_level0_col20\" class=\"col_heading level0 col20\" >PRI_jet_num</th>\n",
       "      <th id=\"T_b3497_level0_col21\" class=\"col_heading level0 col21\" >PRI_jet_leading_pt</th>\n",
       "      <th id=\"T_b3497_level0_col22\" class=\"col_heading level0 col22\" >PRI_jet_leading_eta</th>\n",
       "      <th id=\"T_b3497_level0_col23\" class=\"col_heading level0 col23\" >PRI_jet_leading_phi</th>\n",
       "      <th id=\"T_b3497_level0_col24\" class=\"col_heading level0 col24\" >PRI_jet_subleading_pt</th>\n",
       "      <th id=\"T_b3497_level0_col25\" class=\"col_heading level0 col25\" >PRI_jet_subleading_eta</th>\n",
       "      <th id=\"T_b3497_level0_col26\" class=\"col_heading level0 col26\" >PRI_jet_subleading_phi</th>\n",
       "      <th id=\"T_b3497_level0_col27\" class=\"col_heading level0 col27\" >Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row0\" class=\"row_heading level0 row0\" >DER_mass_MMC</th>\n",
       "      <td id=\"T_b3497_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "      <td id=\"T_b3497_row0_col1\" class=\"data row0 col1\" >0.25</td>\n",
       "      <td id=\"T_b3497_row0_col2\" class=\"data row0 col2\" >0.02</td>\n",
       "      <td id=\"T_b3497_row0_col3\" class=\"data row0 col3\" >-0.03</td>\n",
       "      <td id=\"T_b3497_row0_col4\" class=\"data row0 col4\" >-0.02</td>\n",
       "      <td id=\"T_b3497_row0_col5\" class=\"data row0 col5\" >0.02</td>\n",
       "      <td id=\"T_b3497_row0_col6\" class=\"data row0 col6\" >0.52</td>\n",
       "      <td id=\"T_b3497_row0_col7\" class=\"data row0 col7\" >0.02</td>\n",
       "      <td id=\"T_b3497_row0_col8\" class=\"data row0 col8\" >0.09</td>\n",
       "      <td id=\"T_b3497_row0_col9\" class=\"data row0 col9\" >0.08</td>\n",
       "      <td id=\"T_b3497_row0_col10\" class=\"data row0 col10\" >-0.02</td>\n",
       "      <td id=\"T_b3497_row0_col11\" class=\"data row0 col11\" >-0.04</td>\n",
       "      <td id=\"T_b3497_row0_col12\" class=\"data row0 col12\" >0.18</td>\n",
       "      <td id=\"T_b3497_row0_col13\" class=\"data row0 col13\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row0_col14\" class=\"data row0 col14\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row0_col15\" class=\"data row0 col15\" >0.26</td>\n",
       "      <td id=\"T_b3497_row0_col16\" class=\"data row0 col16\" >0.01</td>\n",
       "      <td id=\"T_b3497_row0_col17\" class=\"data row0 col17\" >0.00</td>\n",
       "      <td id=\"T_b3497_row0_col18\" class=\"data row0 col18\" >0.09</td>\n",
       "      <td id=\"T_b3497_row0_col19\" class=\"data row0 col19\" >0.00</td>\n",
       "      <td id=\"T_b3497_row0_col20\" class=\"data row0 col20\" >0.01</td>\n",
       "      <td id=\"T_b3497_row0_col21\" class=\"data row0 col21\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row0_col22\" class=\"data row0 col22\" >0.00</td>\n",
       "      <td id=\"T_b3497_row0_col23\" class=\"data row0 col23\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row0_col24\" class=\"data row0 col24\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row0_col25\" class=\"data row0 col25\" >0.01</td>\n",
       "      <td id=\"T_b3497_row0_col26\" class=\"data row0 col26\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row0_col27\" class=\"data row0 col27\" >0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row1\" class=\"row_heading level0 row1\" >DER_mass_transverse_met_lep</th>\n",
       "      <td id=\"T_b3497_row1_col0\" class=\"data row1 col0\" >0.25</td>\n",
       "      <td id=\"T_b3497_row1_col1\" class=\"data row1 col1\" >1.00</td>\n",
       "      <td id=\"T_b3497_row1_col2\" class=\"data row1 col2\" >-0.18</td>\n",
       "      <td id=\"T_b3497_row1_col3\" class=\"data row1 col3\" >-0.13</td>\n",
       "      <td id=\"T_b3497_row1_col4\" class=\"data row1 col4\" >-0.14</td>\n",
       "      <td id=\"T_b3497_row1_col5\" class=\"data row1 col5\" >0.12</td>\n",
       "      <td id=\"T_b3497_row1_col6\" class=\"data row1 col6\" >0.19</td>\n",
       "      <td id=\"T_b3497_row1_col7\" class=\"data row1 col7\" >0.10</td>\n",
       "      <td id=\"T_b3497_row1_col8\" class=\"data row1 col8\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row1_col9\" class=\"data row1 col9\" >0.27</td>\n",
       "      <td id=\"T_b3497_row1_col10\" class=\"data row1 col10\" >-0.34</td>\n",
       "      <td id=\"T_b3497_row1_col11\" class=\"data row1 col11\" >-0.11</td>\n",
       "      <td id=\"T_b3497_row1_col12\" class=\"data row1 col12\" >-0.07</td>\n",
       "      <td id=\"T_b3497_row1_col13\" class=\"data row1 col13\" >0.00</td>\n",
       "      <td id=\"T_b3497_row1_col14\" class=\"data row1 col14\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row1_col15\" class=\"data row1 col15\" >0.28</td>\n",
       "      <td id=\"T_b3497_row1_col16\" class=\"data row1 col16\" >0.00</td>\n",
       "      <td id=\"T_b3497_row1_col17\" class=\"data row1 col17\" >0.01</td>\n",
       "      <td id=\"T_b3497_row1_col18\" class=\"data row1 col18\" >-0.06</td>\n",
       "      <td id=\"T_b3497_row1_col19\" class=\"data row1 col19\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row1_col20\" class=\"data row1 col20\" >0.05</td>\n",
       "      <td id=\"T_b3497_row1_col21\" class=\"data row1 col21\" >-0.11</td>\n",
       "      <td id=\"T_b3497_row1_col22\" class=\"data row1 col22\" >0.00</td>\n",
       "      <td id=\"T_b3497_row1_col23\" class=\"data row1 col23\" >0.00</td>\n",
       "      <td id=\"T_b3497_row1_col24\" class=\"data row1 col24\" >-0.03</td>\n",
       "      <td id=\"T_b3497_row1_col25\" class=\"data row1 col25\" >0.00</td>\n",
       "      <td id=\"T_b3497_row1_col26\" class=\"data row1 col26\" >0.01</td>\n",
       "      <td id=\"T_b3497_row1_col27\" class=\"data row1 col27\" >0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row2\" class=\"row_heading level0 row2\" >DER_pt_h</th>\n",
       "      <td id=\"T_b3497_row2_col0\" class=\"data row2 col0\" >0.02</td>\n",
       "      <td id=\"T_b3497_row2_col1\" class=\"data row2 col1\" >-0.18</td>\n",
       "      <td id=\"T_b3497_row2_col2\" class=\"data row2 col2\" >1.00</td>\n",
       "      <td id=\"T_b3497_row2_col3\" class=\"data row2 col3\" >-0.04</td>\n",
       "      <td id=\"T_b3497_row2_col4\" class=\"data row2 col4\" >0.19</td>\n",
       "      <td id=\"T_b3497_row2_col5\" class=\"data row2 col5\" >-0.02</td>\n",
       "      <td id=\"T_b3497_row2_col6\" class=\"data row2 col6\" >-0.67</td>\n",
       "      <td id=\"T_b3497_row2_col7\" class=\"data row2 col7\" >0.16</td>\n",
       "      <td id=\"T_b3497_row2_col8\" class=\"data row2 col8\" >0.72</td>\n",
       "      <td id=\"T_b3497_row2_col9\" class=\"data row2 col9\" >0.10</td>\n",
       "      <td id=\"T_b3497_row2_col10\" class=\"data row2 col10\" >0.36</td>\n",
       "      <td id=\"T_b3497_row2_col11\" class=\"data row2 col11\" >0.01</td>\n",
       "      <td id=\"T_b3497_row2_col12\" class=\"data row2 col12\" >0.45</td>\n",
       "      <td id=\"T_b3497_row2_col13\" class=\"data row2 col13\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row2_col14\" class=\"data row2 col14\" >0.01</td>\n",
       "      <td id=\"T_b3497_row2_col15\" class=\"data row2 col15\" >0.40</td>\n",
       "      <td id=\"T_b3497_row2_col16\" class=\"data row2 col16\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row2_col17\" class=\"data row2 col17\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row2_col18\" class=\"data row2 col18\" >0.78</td>\n",
       "      <td id=\"T_b3497_row2_col19\" class=\"data row2 col19\" >0.01</td>\n",
       "      <td id=\"T_b3497_row2_col20\" class=\"data row2 col20\" >0.14</td>\n",
       "      <td id=\"T_b3497_row2_col21\" class=\"data row2 col21\" >0.75</td>\n",
       "      <td id=\"T_b3497_row2_col22\" class=\"data row2 col22\" >0.00</td>\n",
       "      <td id=\"T_b3497_row2_col23\" class=\"data row2 col23\" >0.00</td>\n",
       "      <td id=\"T_b3497_row2_col24\" class=\"data row2 col24\" >0.36</td>\n",
       "      <td id=\"T_b3497_row2_col25\" class=\"data row2 col25\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row2_col26\" class=\"data row2 col26\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row2_col27\" class=\"data row2 col27\" >-0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row3\" class=\"row_heading level0 row3\" >DER_deltaeta_jet_jet</th>\n",
       "      <td id=\"T_b3497_row3_col0\" class=\"data row3 col0\" >-0.03</td>\n",
       "      <td id=\"T_b3497_row3_col1\" class=\"data row3 col1\" >-0.13</td>\n",
       "      <td id=\"T_b3497_row3_col2\" class=\"data row3 col2\" >-0.04</td>\n",
       "      <td id=\"T_b3497_row3_col3\" class=\"data row3 col3\" >1.00</td>\n",
       "      <td id=\"T_b3497_row3_col4\" class=\"data row3 col4\" >0.80</td>\n",
       "      <td id=\"T_b3497_row3_col5\" class=\"data row3 col5\" >-0.84</td>\n",
       "      <td id=\"T_b3497_row3_col6\" class=\"data row3 col6\" >0.04</td>\n",
       "      <td id=\"T_b3497_row3_col7\" class=\"data row3 col7\" >-0.18</td>\n",
       "      <td id=\"T_b3497_row3_col8\" class=\"data row3 col8\" >-0.11</td>\n",
       "      <td id=\"T_b3497_row3_col9\" class=\"data row3 col9\" >-0.08</td>\n",
       "      <td id=\"T_b3497_row3_col10\" class=\"data row3 col10\" >0.10</td>\n",
       "      <td id=\"T_b3497_row3_col11\" class=\"data row3 col11\" >0.64</td>\n",
       "      <td id=\"T_b3497_row3_col12\" class=\"data row3 col12\" >0.01</td>\n",
       "      <td id=\"T_b3497_row3_col13\" class=\"data row3 col13\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row3_col14\" class=\"data row3 col14\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row3_col15\" class=\"data row3 col15\" >-0.08</td>\n",
       "      <td id=\"T_b3497_row3_col16\" class=\"data row3 col16\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row3_col17\" class=\"data row3 col17\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row3_col18\" class=\"data row3 col18\" >-0.05</td>\n",
       "      <td id=\"T_b3497_row3_col19\" class=\"data row3 col19\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row3_col20\" class=\"data row3 col20\" >-0.18</td>\n",
       "      <td id=\"T_b3497_row3_col21\" class=\"data row3 col21\" >-0.05</td>\n",
       "      <td id=\"T_b3497_row3_col22\" class=\"data row3 col22\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row3_col23\" class=\"data row3 col23\" >0.00</td>\n",
       "      <td id=\"T_b3497_row3_col24\" class=\"data row3 col24\" >-0.09</td>\n",
       "      <td id=\"T_b3497_row3_col25\" class=\"data row3 col25\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row3_col26\" class=\"data row3 col26\" >0.00</td>\n",
       "      <td id=\"T_b3497_row3_col27\" class=\"data row3 col27\" >-0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row4\" class=\"row_heading level0 row4\" >DER_mass_jet_jet</th>\n",
       "      <td id=\"T_b3497_row4_col0\" class=\"data row4 col0\" >-0.02</td>\n",
       "      <td id=\"T_b3497_row4_col1\" class=\"data row4 col1\" >-0.14</td>\n",
       "      <td id=\"T_b3497_row4_col2\" class=\"data row4 col2\" >0.19</td>\n",
       "      <td id=\"T_b3497_row4_col3\" class=\"data row4 col3\" >0.80</td>\n",
       "      <td id=\"T_b3497_row4_col4\" class=\"data row4 col4\" >1.00</td>\n",
       "      <td id=\"T_b3497_row4_col5\" class=\"data row4 col5\" >-0.76</td>\n",
       "      <td id=\"T_b3497_row4_col6\" class=\"data row4 col6\" >-0.12</td>\n",
       "      <td id=\"T_b3497_row4_col7\" class=\"data row4 col7\" >-0.07</td>\n",
       "      <td id=\"T_b3497_row4_col8\" class=\"data row4 col8\" >0.23</td>\n",
       "      <td id=\"T_b3497_row4_col9\" class=\"data row4 col9\" >-0.05</td>\n",
       "      <td id=\"T_b3497_row4_col10\" class=\"data row4 col10\" >0.15</td>\n",
       "      <td id=\"T_b3497_row4_col11\" class=\"data row4 col11\" >0.48</td>\n",
       "      <td id=\"T_b3497_row4_col12\" class=\"data row4 col12\" >0.11</td>\n",
       "      <td id=\"T_b3497_row4_col13\" class=\"data row4 col13\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row4_col14\" class=\"data row4 col14\" >0.00</td>\n",
       "      <td id=\"T_b3497_row4_col15\" class=\"data row4 col15\" >0.02</td>\n",
       "      <td id=\"T_b3497_row4_col16\" class=\"data row4 col16\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row4_col17\" class=\"data row4 col17\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row4_col18\" class=\"data row4 col18\" >0.14</td>\n",
       "      <td id=\"T_b3497_row4_col19\" class=\"data row4 col19\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row4_col20\" class=\"data row4 col20\" >-0.08</td>\n",
       "      <td id=\"T_b3497_row4_col21\" class=\"data row4 col21\" >0.28</td>\n",
       "      <td id=\"T_b3497_row4_col22\" class=\"data row4 col22\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row4_col23\" class=\"data row4 col23\" >0.00</td>\n",
       "      <td id=\"T_b3497_row4_col24\" class=\"data row4 col24\" >0.23</td>\n",
       "      <td id=\"T_b3497_row4_col25\" class=\"data row4 col25\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row4_col26\" class=\"data row4 col26\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row4_col27\" class=\"data row4 col27\" >-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row5\" class=\"row_heading level0 row5\" >DER_prodeta_jet_jet</th>\n",
       "      <td id=\"T_b3497_row5_col0\" class=\"data row5 col0\" >0.02</td>\n",
       "      <td id=\"T_b3497_row5_col1\" class=\"data row5 col1\" >0.12</td>\n",
       "      <td id=\"T_b3497_row5_col2\" class=\"data row5 col2\" >-0.02</td>\n",
       "      <td id=\"T_b3497_row5_col3\" class=\"data row5 col3\" >-0.84</td>\n",
       "      <td id=\"T_b3497_row5_col4\" class=\"data row5 col4\" >-0.76</td>\n",
       "      <td id=\"T_b3497_row5_col5\" class=\"data row5 col5\" >1.00</td>\n",
       "      <td id=\"T_b3497_row5_col6\" class=\"data row5 col6\" >0.01</td>\n",
       "      <td id=\"T_b3497_row5_col7\" class=\"data row5 col7\" >0.13</td>\n",
       "      <td id=\"T_b3497_row5_col8\" class=\"data row5 col8\" >0.02</td>\n",
       "      <td id=\"T_b3497_row5_col9\" class=\"data row5 col9\" >0.06</td>\n",
       "      <td id=\"T_b3497_row5_col10\" class=\"data row5 col10\" >-0.10</td>\n",
       "      <td id=\"T_b3497_row5_col11\" class=\"data row5 col11\" >-0.56</td>\n",
       "      <td id=\"T_b3497_row5_col12\" class=\"data row5 col12\" >-0.04</td>\n",
       "      <td id=\"T_b3497_row5_col13\" class=\"data row5 col13\" >0.01</td>\n",
       "      <td id=\"T_b3497_row5_col14\" class=\"data row5 col14\" >0.00</td>\n",
       "      <td id=\"T_b3497_row5_col15\" class=\"data row5 col15\" >0.04</td>\n",
       "      <td id=\"T_b3497_row5_col16\" class=\"data row5 col16\" >0.00</td>\n",
       "      <td id=\"T_b3497_row5_col17\" class=\"data row5 col17\" >0.01</td>\n",
       "      <td id=\"T_b3497_row5_col18\" class=\"data row5 col18\" >0.00</td>\n",
       "      <td id=\"T_b3497_row5_col19\" class=\"data row5 col19\" >0.01</td>\n",
       "      <td id=\"T_b3497_row5_col20\" class=\"data row5 col20\" >0.12</td>\n",
       "      <td id=\"T_b3497_row5_col21\" class=\"data row5 col21\" >-0.02</td>\n",
       "      <td id=\"T_b3497_row5_col22\" class=\"data row5 col22\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row5_col23\" class=\"data row5 col23\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row5_col24\" class=\"data row5 col24\" >0.01</td>\n",
       "      <td id=\"T_b3497_row5_col25\" class=\"data row5 col25\" >0.00</td>\n",
       "      <td id=\"T_b3497_row5_col26\" class=\"data row5 col26\" >0.00</td>\n",
       "      <td id=\"T_b3497_row5_col27\" class=\"data row5 col27\" >0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row6\" class=\"row_heading level0 row6\" >DER_deltar_tau_lep</th>\n",
       "      <td id=\"T_b3497_row6_col0\" class=\"data row6 col0\" >0.52</td>\n",
       "      <td id=\"T_b3497_row6_col1\" class=\"data row6 col1\" >0.19</td>\n",
       "      <td id=\"T_b3497_row6_col2\" class=\"data row6 col2\" >-0.67</td>\n",
       "      <td id=\"T_b3497_row6_col3\" class=\"data row6 col3\" >0.04</td>\n",
       "      <td id=\"T_b3497_row6_col4\" class=\"data row6 col4\" >-0.12</td>\n",
       "      <td id=\"T_b3497_row6_col5\" class=\"data row6 col5\" >0.01</td>\n",
       "      <td id=\"T_b3497_row6_col6\" class=\"data row6 col6\" >1.00</td>\n",
       "      <td id=\"T_b3497_row6_col7\" class=\"data row6 col7\" >-0.11</td>\n",
       "      <td id=\"T_b3497_row6_col8\" class=\"data row6 col8\" >-0.45</td>\n",
       "      <td id=\"T_b3497_row6_col9\" class=\"data row6 col9\" >0.09</td>\n",
       "      <td id=\"T_b3497_row6_col10\" class=\"data row6 col10\" >-0.25</td>\n",
       "      <td id=\"T_b3497_row6_col11\" class=\"data row6 col11\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row6_col12\" class=\"data row6 col12\" >-0.32</td>\n",
       "      <td id=\"T_b3497_row6_col13\" class=\"data row6 col13\" >0.00</td>\n",
       "      <td id=\"T_b3497_row6_col14\" class=\"data row6 col14\" >-0.02</td>\n",
       "      <td id=\"T_b3497_row6_col15\" class=\"data row6 col15\" >-0.12</td>\n",
       "      <td id=\"T_b3497_row6_col16\" class=\"data row6 col16\" >0.01</td>\n",
       "      <td id=\"T_b3497_row6_col17\" class=\"data row6 col17\" >0.01</td>\n",
       "      <td id=\"T_b3497_row6_col18\" class=\"data row6 col18\" >-0.41</td>\n",
       "      <td id=\"T_b3497_row6_col19\" class=\"data row6 col19\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row6_col20\" class=\"data row6 col20\" >-0.11</td>\n",
       "      <td id=\"T_b3497_row6_col21\" class=\"data row6 col21\" >-0.48</td>\n",
       "      <td id=\"T_b3497_row6_col22\" class=\"data row6 col22\" >0.01</td>\n",
       "      <td id=\"T_b3497_row6_col23\" class=\"data row6 col23\" >0.00</td>\n",
       "      <td id=\"T_b3497_row6_col24\" class=\"data row6 col24\" >-0.24</td>\n",
       "      <td id=\"T_b3497_row6_col25\" class=\"data row6 col25\" >0.01</td>\n",
       "      <td id=\"T_b3497_row6_col26\" class=\"data row6 col26\" >0.01</td>\n",
       "      <td id=\"T_b3497_row6_col27\" class=\"data row6 col27\" >0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row7\" class=\"row_heading level0 row7\" >DER_pt_tot</th>\n",
       "      <td id=\"T_b3497_row7_col0\" class=\"data row7 col0\" >0.02</td>\n",
       "      <td id=\"T_b3497_row7_col1\" class=\"data row7 col1\" >0.10</td>\n",
       "      <td id=\"T_b3497_row7_col2\" class=\"data row7 col2\" >0.16</td>\n",
       "      <td id=\"T_b3497_row7_col3\" class=\"data row7 col3\" >-0.18</td>\n",
       "      <td id=\"T_b3497_row7_col4\" class=\"data row7 col4\" >-0.07</td>\n",
       "      <td id=\"T_b3497_row7_col5\" class=\"data row7 col5\" >0.13</td>\n",
       "      <td id=\"T_b3497_row7_col6\" class=\"data row7 col6\" >-0.11</td>\n",
       "      <td id=\"T_b3497_row7_col7\" class=\"data row7 col7\" >1.00</td>\n",
       "      <td id=\"T_b3497_row7_col8\" class=\"data row7 col8\" >0.42</td>\n",
       "      <td id=\"T_b3497_row7_col9\" class=\"data row7 col9\" >0.05</td>\n",
       "      <td id=\"T_b3497_row7_col10\" class=\"data row7 col10\" >-0.04</td>\n",
       "      <td id=\"T_b3497_row7_col11\" class=\"data row7 col11\" >-0.15</td>\n",
       "      <td id=\"T_b3497_row7_col12\" class=\"data row7 col12\" >0.05</td>\n",
       "      <td id=\"T_b3497_row7_col13\" class=\"data row7 col13\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row7_col14\" class=\"data row7 col14\" >0.01</td>\n",
       "      <td id=\"T_b3497_row7_col15\" class=\"data row7 col15\" >0.10</td>\n",
       "      <td id=\"T_b3497_row7_col16\" class=\"data row7 col16\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row7_col17\" class=\"data row7 col17\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row7_col18\" class=\"data row7 col18\" >0.15</td>\n",
       "      <td id=\"T_b3497_row7_col19\" class=\"data row7 col19\" >0.00</td>\n",
       "      <td id=\"T_b3497_row7_col20\" class=\"data row7 col20\" >0.60</td>\n",
       "      <td id=\"T_b3497_row7_col21\" class=\"data row7 col21\" >0.19</td>\n",
       "      <td id=\"T_b3497_row7_col22\" class=\"data row7 col22\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row7_col23\" class=\"data row7 col23\" >0.00</td>\n",
       "      <td id=\"T_b3497_row7_col24\" class=\"data row7 col24\" >0.33</td>\n",
       "      <td id=\"T_b3497_row7_col25\" class=\"data row7 col25\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row7_col26\" class=\"data row7 col26\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row7_col27\" class=\"data row7 col27\" >-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row8\" class=\"row_heading level0 row8\" >DER_sum_pt</th>\n",
       "      <td id=\"T_b3497_row8_col0\" class=\"data row8 col0\" >0.09</td>\n",
       "      <td id=\"T_b3497_row8_col1\" class=\"data row8 col1\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row8_col2\" class=\"data row8 col2\" >0.72</td>\n",
       "      <td id=\"T_b3497_row8_col3\" class=\"data row8 col3\" >-0.11</td>\n",
       "      <td id=\"T_b3497_row8_col4\" class=\"data row8 col4\" >0.23</td>\n",
       "      <td id=\"T_b3497_row8_col5\" class=\"data row8 col5\" >0.02</td>\n",
       "      <td id=\"T_b3497_row8_col6\" class=\"data row8 col6\" >-0.45</td>\n",
       "      <td id=\"T_b3497_row8_col7\" class=\"data row8 col7\" >0.42</td>\n",
       "      <td id=\"T_b3497_row8_col8\" class=\"data row8 col8\" >1.00</td>\n",
       "      <td id=\"T_b3497_row8_col9\" class=\"data row8 col9\" >0.13</td>\n",
       "      <td id=\"T_b3497_row8_col10\" class=\"data row8 col10\" >0.14</td>\n",
       "      <td id=\"T_b3497_row8_col11\" class=\"data row8 col11\" >-0.04</td>\n",
       "      <td id=\"T_b3497_row8_col12\" class=\"data row8 col12\" >0.46</td>\n",
       "      <td id=\"T_b3497_row8_col13\" class=\"data row8 col13\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row8_col14\" class=\"data row8 col14\" >0.01</td>\n",
       "      <td id=\"T_b3497_row8_col15\" class=\"data row8 col15\" >0.45</td>\n",
       "      <td id=\"T_b3497_row8_col16\" class=\"data row8 col16\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row8_col17\" class=\"data row8 col17\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row8_col18\" class=\"data row8 col18\" >0.49</td>\n",
       "      <td id=\"T_b3497_row8_col19\" class=\"data row8 col19\" >0.00</td>\n",
       "      <td id=\"T_b3497_row8_col20\" class=\"data row8 col20\" >0.40</td>\n",
       "      <td id=\"T_b3497_row8_col21\" class=\"data row8 col21\" >0.88</td>\n",
       "      <td id=\"T_b3497_row8_col22\" class=\"data row8 col22\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row8_col23\" class=\"data row8 col23\" >0.00</td>\n",
       "      <td id=\"T_b3497_row8_col24\" class=\"data row8 col24\" >0.73</td>\n",
       "      <td id=\"T_b3497_row8_col25\" class=\"data row8 col25\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row8_col26\" class=\"data row8 col26\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row8_col27\" class=\"data row8 col27\" >-0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row9\" class=\"row_heading level0 row9\" >DER_pt_ratio_lep_tau</th>\n",
       "      <td id=\"T_b3497_row9_col0\" class=\"data row9 col0\" >0.08</td>\n",
       "      <td id=\"T_b3497_row9_col1\" class=\"data row9 col1\" >0.27</td>\n",
       "      <td id=\"T_b3497_row9_col2\" class=\"data row9 col2\" >0.10</td>\n",
       "      <td id=\"T_b3497_row9_col3\" class=\"data row9 col3\" >-0.08</td>\n",
       "      <td id=\"T_b3497_row9_col4\" class=\"data row9 col4\" >-0.05</td>\n",
       "      <td id=\"T_b3497_row9_col5\" class=\"data row9 col5\" >0.06</td>\n",
       "      <td id=\"T_b3497_row9_col6\" class=\"data row9 col6\" >0.09</td>\n",
       "      <td id=\"T_b3497_row9_col7\" class=\"data row9 col7\" >0.05</td>\n",
       "      <td id=\"T_b3497_row9_col8\" class=\"data row9 col8\" >0.13</td>\n",
       "      <td id=\"T_b3497_row9_col9\" class=\"data row9 col9\" >1.00</td>\n",
       "      <td id=\"T_b3497_row9_col10\" class=\"data row9 col10\" >-0.08</td>\n",
       "      <td id=\"T_b3497_row9_col11\" class=\"data row9 col11\" >-0.06</td>\n",
       "      <td id=\"T_b3497_row9_col12\" class=\"data row9 col12\" >-0.47</td>\n",
       "      <td id=\"T_b3497_row9_col13\" class=\"data row9 col13\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row9_col14\" class=\"data row9 col14\" >0.00</td>\n",
       "      <td id=\"T_b3497_row9_col15\" class=\"data row9 col15\" >0.75</td>\n",
       "      <td id=\"T_b3497_row9_col16\" class=\"data row9 col16\" >0.00</td>\n",
       "      <td id=\"T_b3497_row9_col17\" class=\"data row9 col17\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row9_col18\" class=\"data row9 col18\" >0.00</td>\n",
       "      <td id=\"T_b3497_row9_col19\" class=\"data row9 col19\" >0.00</td>\n",
       "      <td id=\"T_b3497_row9_col20\" class=\"data row9 col20\" >0.06</td>\n",
       "      <td id=\"T_b3497_row9_col21\" class=\"data row9 col21\" >0.07</td>\n",
       "      <td id=\"T_b3497_row9_col22\" class=\"data row9 col22\" >0.00</td>\n",
       "      <td id=\"T_b3497_row9_col23\" class=\"data row9 col23\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row9_col24\" class=\"data row9 col24\" >0.05</td>\n",
       "      <td id=\"T_b3497_row9_col25\" class=\"data row9 col25\" >0.00</td>\n",
       "      <td id=\"T_b3497_row9_col26\" class=\"data row9 col26\" >0.00</td>\n",
       "      <td id=\"T_b3497_row9_col27\" class=\"data row9 col27\" >0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row10\" class=\"row_heading level0 row10\" >DER_met_phi_centrality</th>\n",
       "      <td id=\"T_b3497_row10_col0\" class=\"data row10 col0\" >-0.02</td>\n",
       "      <td id=\"T_b3497_row10_col1\" class=\"data row10 col1\" >-0.34</td>\n",
       "      <td id=\"T_b3497_row10_col2\" class=\"data row10 col2\" >0.36</td>\n",
       "      <td id=\"T_b3497_row10_col3\" class=\"data row10 col3\" >0.10</td>\n",
       "      <td id=\"T_b3497_row10_col4\" class=\"data row10 col4\" >0.15</td>\n",
       "      <td id=\"T_b3497_row10_col5\" class=\"data row10 col5\" >-0.10</td>\n",
       "      <td id=\"T_b3497_row10_col6\" class=\"data row10 col6\" >-0.25</td>\n",
       "      <td id=\"T_b3497_row10_col7\" class=\"data row10 col7\" >-0.04</td>\n",
       "      <td id=\"T_b3497_row10_col8\" class=\"data row10 col8\" >0.14</td>\n",
       "      <td id=\"T_b3497_row10_col9\" class=\"data row10 col9\" >-0.08</td>\n",
       "      <td id=\"T_b3497_row10_col10\" class=\"data row10 col10\" >1.00</td>\n",
       "      <td id=\"T_b3497_row10_col11\" class=\"data row10 col11\" >0.10</td>\n",
       "      <td id=\"T_b3497_row10_col12\" class=\"data row10 col12\" >0.07</td>\n",
       "      <td id=\"T_b3497_row10_col13\" class=\"data row10 col13\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row10_col14\" class=\"data row10 col14\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row10_col15\" class=\"data row10 col15\" >-0.04</td>\n",
       "      <td id=\"T_b3497_row10_col16\" class=\"data row10 col16\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row10_col17\" class=\"data row10 col17\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row10_col18\" class=\"data row10 col18\" >0.25</td>\n",
       "      <td id=\"T_b3497_row10_col19\" class=\"data row10 col19\" >0.00</td>\n",
       "      <td id=\"T_b3497_row10_col20\" class=\"data row10 col20\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row10_col21\" class=\"data row10 col21\" >0.21</td>\n",
       "      <td id=\"T_b3497_row10_col22\" class=\"data row10 col22\" >0.01</td>\n",
       "      <td id=\"T_b3497_row10_col23\" class=\"data row10 col23\" >0.00</td>\n",
       "      <td id=\"T_b3497_row10_col24\" class=\"data row10 col24\" >0.08</td>\n",
       "      <td id=\"T_b3497_row10_col25\" class=\"data row10 col25\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row10_col26\" class=\"data row10 col26\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row10_col27\" class=\"data row10 col27\" >-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row11\" class=\"row_heading level0 row11\" >DER_lep_eta_centrality</th>\n",
       "      <td id=\"T_b3497_row11_col0\" class=\"data row11 col0\" >-0.04</td>\n",
       "      <td id=\"T_b3497_row11_col1\" class=\"data row11 col1\" >-0.11</td>\n",
       "      <td id=\"T_b3497_row11_col2\" class=\"data row11 col2\" >0.01</td>\n",
       "      <td id=\"T_b3497_row11_col3\" class=\"data row11 col3\" >0.64</td>\n",
       "      <td id=\"T_b3497_row11_col4\" class=\"data row11 col4\" >0.48</td>\n",
       "      <td id=\"T_b3497_row11_col5\" class=\"data row11 col5\" >-0.56</td>\n",
       "      <td id=\"T_b3497_row11_col6\" class=\"data row11 col6\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row11_col7\" class=\"data row11 col7\" >-0.15</td>\n",
       "      <td id=\"T_b3497_row11_col8\" class=\"data row11 col8\" >-0.04</td>\n",
       "      <td id=\"T_b3497_row11_col9\" class=\"data row11 col9\" >-0.06</td>\n",
       "      <td id=\"T_b3497_row11_col10\" class=\"data row11 col10\" >0.10</td>\n",
       "      <td id=\"T_b3497_row11_col11\" class=\"data row11 col11\" >1.00</td>\n",
       "      <td id=\"T_b3497_row11_col12\" class=\"data row11 col12\" >0.03</td>\n",
       "      <td id=\"T_b3497_row11_col13\" class=\"data row11 col13\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row11_col14\" class=\"data row11 col14\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row11_col15\" class=\"data row11 col15\" >-0.04</td>\n",
       "      <td id=\"T_b3497_row11_col16\" class=\"data row11 col16\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row11_col17\" class=\"data row11 col17\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row11_col18\" class=\"data row11 col18\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row11_col19\" class=\"data row11 col19\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row11_col20\" class=\"data row11 col20\" >-0.13</td>\n",
       "      <td id=\"T_b3497_row11_col21\" class=\"data row11 col21\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row11_col22\" class=\"data row11 col22\" >0.00</td>\n",
       "      <td id=\"T_b3497_row11_col23\" class=\"data row11 col23\" >0.00</td>\n",
       "      <td id=\"T_b3497_row11_col24\" class=\"data row11 col24\" >-0.03</td>\n",
       "      <td id=\"T_b3497_row11_col25\" class=\"data row11 col25\" >0.00</td>\n",
       "      <td id=\"T_b3497_row11_col26\" class=\"data row11 col26\" >0.00</td>\n",
       "      <td id=\"T_b3497_row11_col27\" class=\"data row11 col27\" >-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row12\" class=\"row_heading level0 row12\" >PRI_tau_pt</th>\n",
       "      <td id=\"T_b3497_row12_col0\" class=\"data row12 col0\" >0.18</td>\n",
       "      <td id=\"T_b3497_row12_col1\" class=\"data row12 col1\" >-0.07</td>\n",
       "      <td id=\"T_b3497_row12_col2\" class=\"data row12 col2\" >0.45</td>\n",
       "      <td id=\"T_b3497_row12_col3\" class=\"data row12 col3\" >0.01</td>\n",
       "      <td id=\"T_b3497_row12_col4\" class=\"data row12 col4\" >0.11</td>\n",
       "      <td id=\"T_b3497_row12_col5\" class=\"data row12 col5\" >-0.04</td>\n",
       "      <td id=\"T_b3497_row12_col6\" class=\"data row12 col6\" >-0.32</td>\n",
       "      <td id=\"T_b3497_row12_col7\" class=\"data row12 col7\" >0.05</td>\n",
       "      <td id=\"T_b3497_row12_col8\" class=\"data row12 col8\" >0.46</td>\n",
       "      <td id=\"T_b3497_row12_col9\" class=\"data row12 col9\" >-0.47</td>\n",
       "      <td id=\"T_b3497_row12_col10\" class=\"data row12 col10\" >0.07</td>\n",
       "      <td id=\"T_b3497_row12_col11\" class=\"data row12 col11\" >0.03</td>\n",
       "      <td id=\"T_b3497_row12_col12\" class=\"data row12 col12\" >1.00</td>\n",
       "      <td id=\"T_b3497_row12_col13\" class=\"data row12 col13\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row12_col14\" class=\"data row12 col14\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row12_col15\" class=\"data row12 col15\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row12_col16\" class=\"data row12 col16\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row12_col17\" class=\"data row12 col17\" >0.00</td>\n",
       "      <td id=\"T_b3497_row12_col18\" class=\"data row12 col18\" >0.14</td>\n",
       "      <td id=\"T_b3497_row12_col19\" class=\"data row12 col19\" >0.00</td>\n",
       "      <td id=\"T_b3497_row12_col20\" class=\"data row12 col20\" >0.03</td>\n",
       "      <td id=\"T_b3497_row12_col21\" class=\"data row12 col21\" >0.35</td>\n",
       "      <td id=\"T_b3497_row12_col22\" class=\"data row12 col22\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row12_col23\" class=\"data row12 col23\" >0.00</td>\n",
       "      <td id=\"T_b3497_row12_col24\" class=\"data row12 col24\" >0.15</td>\n",
       "      <td id=\"T_b3497_row12_col25\" class=\"data row12 col25\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row12_col26\" class=\"data row12 col26\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row12_col27\" class=\"data row12 col27\" >-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row13\" class=\"row_heading level0 row13\" >PRI_tau_eta</th>\n",
       "      <td id=\"T_b3497_row13_col0\" class=\"data row13 col0\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row13_col1\" class=\"data row13 col1\" >0.00</td>\n",
       "      <td id=\"T_b3497_row13_col2\" class=\"data row13 col2\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row13_col3\" class=\"data row13 col3\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row13_col4\" class=\"data row13 col4\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row13_col5\" class=\"data row13 col5\" >0.01</td>\n",
       "      <td id=\"T_b3497_row13_col6\" class=\"data row13 col6\" >0.00</td>\n",
       "      <td id=\"T_b3497_row13_col7\" class=\"data row13 col7\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row13_col8\" class=\"data row13 col8\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row13_col9\" class=\"data row13 col9\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row13_col10\" class=\"data row13 col10\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row13_col11\" class=\"data row13 col11\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row13_col12\" class=\"data row13 col12\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row13_col13\" class=\"data row13 col13\" >1.00</td>\n",
       "      <td id=\"T_b3497_row13_col14\" class=\"data row13 col14\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row13_col15\" class=\"data row13 col15\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row13_col16\" class=\"data row13 col16\" >0.60</td>\n",
       "      <td id=\"T_b3497_row13_col17\" class=\"data row13 col17\" >0.00</td>\n",
       "      <td id=\"T_b3497_row13_col18\" class=\"data row13 col18\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row13_col19\" class=\"data row13 col19\" >0.00</td>\n",
       "      <td id=\"T_b3497_row13_col20\" class=\"data row13 col20\" >0.00</td>\n",
       "      <td id=\"T_b3497_row13_col21\" class=\"data row13 col21\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row13_col22\" class=\"data row13 col22\" >0.19</td>\n",
       "      <td id=\"T_b3497_row13_col23\" class=\"data row13 col23\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row13_col24\" class=\"data row13 col24\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row13_col25\" class=\"data row13 col25\" >0.15</td>\n",
       "      <td id=\"T_b3497_row13_col26\" class=\"data row13 col26\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row13_col27\" class=\"data row13 col27\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row14\" class=\"row_heading level0 row14\" >PRI_tau_phi</th>\n",
       "      <td id=\"T_b3497_row14_col0\" class=\"data row14 col0\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row14_col1\" class=\"data row14 col1\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row14_col2\" class=\"data row14 col2\" >0.01</td>\n",
       "      <td id=\"T_b3497_row14_col3\" class=\"data row14 col3\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row14_col4\" class=\"data row14 col4\" >0.00</td>\n",
       "      <td id=\"T_b3497_row14_col5\" class=\"data row14 col5\" >0.00</td>\n",
       "      <td id=\"T_b3497_row14_col6\" class=\"data row14 col6\" >-0.02</td>\n",
       "      <td id=\"T_b3497_row14_col7\" class=\"data row14 col7\" >0.01</td>\n",
       "      <td id=\"T_b3497_row14_col8\" class=\"data row14 col8\" >0.01</td>\n",
       "      <td id=\"T_b3497_row14_col9\" class=\"data row14 col9\" >0.00</td>\n",
       "      <td id=\"T_b3497_row14_col10\" class=\"data row14 col10\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row14_col11\" class=\"data row14 col11\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row14_col12\" class=\"data row14 col12\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row14_col13\" class=\"data row14 col13\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row14_col14\" class=\"data row14 col14\" >1.00</td>\n",
       "      <td id=\"T_b3497_row14_col15\" class=\"data row14 col15\" >0.00</td>\n",
       "      <td id=\"T_b3497_row14_col16\" class=\"data row14 col16\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row14_col17\" class=\"data row14 col17\" >-0.06</td>\n",
       "      <td id=\"T_b3497_row14_col18\" class=\"data row14 col18\" >0.01</td>\n",
       "      <td id=\"T_b3497_row14_col19\" class=\"data row14 col19\" >0.17</td>\n",
       "      <td id=\"T_b3497_row14_col20\" class=\"data row14 col20\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row14_col21\" class=\"data row14 col21\" >0.01</td>\n",
       "      <td id=\"T_b3497_row14_col22\" class=\"data row14 col22\" >0.01</td>\n",
       "      <td id=\"T_b3497_row14_col23\" class=\"data row14 col23\" >-0.22</td>\n",
       "      <td id=\"T_b3497_row14_col24\" class=\"data row14 col24\" >0.00</td>\n",
       "      <td id=\"T_b3497_row14_col25\" class=\"data row14 col25\" >0.00</td>\n",
       "      <td id=\"T_b3497_row14_col26\" class=\"data row14 col26\" >-0.11</td>\n",
       "      <td id=\"T_b3497_row14_col27\" class=\"data row14 col27\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row15\" class=\"row_heading level0 row15\" >PRI_lep_pt</th>\n",
       "      <td id=\"T_b3497_row15_col0\" class=\"data row15 col0\" >0.26</td>\n",
       "      <td id=\"T_b3497_row15_col1\" class=\"data row15 col1\" >0.28</td>\n",
       "      <td id=\"T_b3497_row15_col2\" class=\"data row15 col2\" >0.40</td>\n",
       "      <td id=\"T_b3497_row15_col3\" class=\"data row15 col3\" >-0.08</td>\n",
       "      <td id=\"T_b3497_row15_col4\" class=\"data row15 col4\" >0.02</td>\n",
       "      <td id=\"T_b3497_row15_col5\" class=\"data row15 col5\" >0.04</td>\n",
       "      <td id=\"T_b3497_row15_col6\" class=\"data row15 col6\" >-0.12</td>\n",
       "      <td id=\"T_b3497_row15_col7\" class=\"data row15 col7\" >0.10</td>\n",
       "      <td id=\"T_b3497_row15_col8\" class=\"data row15 col8\" >0.45</td>\n",
       "      <td id=\"T_b3497_row15_col9\" class=\"data row15 col9\" >0.75</td>\n",
       "      <td id=\"T_b3497_row15_col10\" class=\"data row15 col10\" >-0.04</td>\n",
       "      <td id=\"T_b3497_row15_col11\" class=\"data row15 col11\" >-0.04</td>\n",
       "      <td id=\"T_b3497_row15_col12\" class=\"data row15 col12\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row15_col13\" class=\"data row15 col13\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row15_col14\" class=\"data row15 col14\" >0.00</td>\n",
       "      <td id=\"T_b3497_row15_col15\" class=\"data row15 col15\" >1.00</td>\n",
       "      <td id=\"T_b3497_row15_col16\" class=\"data row15 col16\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row15_col17\" class=\"data row15 col17\" >0.00</td>\n",
       "      <td id=\"T_b3497_row15_col18\" class=\"data row15 col18\" >0.11</td>\n",
       "      <td id=\"T_b3497_row15_col19\" class=\"data row15 col19\" >0.00</td>\n",
       "      <td id=\"T_b3497_row15_col20\" class=\"data row15 col20\" >0.08</td>\n",
       "      <td id=\"T_b3497_row15_col21\" class=\"data row15 col21\" >0.30</td>\n",
       "      <td id=\"T_b3497_row15_col22\" class=\"data row15 col22\" >0.00</td>\n",
       "      <td id=\"T_b3497_row15_col23\" class=\"data row15 col23\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row15_col24\" class=\"data row15 col24\" >0.15</td>\n",
       "      <td id=\"T_b3497_row15_col25\" class=\"data row15 col25\" >0.00</td>\n",
       "      <td id=\"T_b3497_row15_col26\" class=\"data row15 col26\" >0.00</td>\n",
       "      <td id=\"T_b3497_row15_col27\" class=\"data row15 col27\" >0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row16\" class=\"row_heading level0 row16\" >PRI_lep_eta</th>\n",
       "      <td id=\"T_b3497_row16_col0\" class=\"data row16 col0\" >0.01</td>\n",
       "      <td id=\"T_b3497_row16_col1\" class=\"data row16 col1\" >0.00</td>\n",
       "      <td id=\"T_b3497_row16_col2\" class=\"data row16 col2\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row16_col3\" class=\"data row16 col3\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row16_col4\" class=\"data row16 col4\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row16_col5\" class=\"data row16 col5\" >0.00</td>\n",
       "      <td id=\"T_b3497_row16_col6\" class=\"data row16 col6\" >0.01</td>\n",
       "      <td id=\"T_b3497_row16_col7\" class=\"data row16 col7\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row16_col8\" class=\"data row16 col8\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row16_col9\" class=\"data row16 col9\" >0.00</td>\n",
       "      <td id=\"T_b3497_row16_col10\" class=\"data row16 col10\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row16_col11\" class=\"data row16 col11\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row16_col12\" class=\"data row16 col12\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row16_col13\" class=\"data row16 col13\" >0.60</td>\n",
       "      <td id=\"T_b3497_row16_col14\" class=\"data row16 col14\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row16_col15\" class=\"data row16 col15\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row16_col16\" class=\"data row16 col16\" >1.00</td>\n",
       "      <td id=\"T_b3497_row16_col17\" class=\"data row16 col17\" >0.00</td>\n",
       "      <td id=\"T_b3497_row16_col18\" class=\"data row16 col18\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row16_col19\" class=\"data row16 col19\" >0.00</td>\n",
       "      <td id=\"T_b3497_row16_col20\" class=\"data row16 col20\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row16_col21\" class=\"data row16 col21\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row16_col22\" class=\"data row16 col22\" >0.21</td>\n",
       "      <td id=\"T_b3497_row16_col23\" class=\"data row16 col23\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row16_col24\" class=\"data row16 col24\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row16_col25\" class=\"data row16 col25\" >0.16</td>\n",
       "      <td id=\"T_b3497_row16_col26\" class=\"data row16 col26\" >0.00</td>\n",
       "      <td id=\"T_b3497_row16_col27\" class=\"data row16 col27\" >0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row17\" class=\"row_heading level0 row17\" >PRI_lep_phi</th>\n",
       "      <td id=\"T_b3497_row17_col0\" class=\"data row17 col0\" >0.00</td>\n",
       "      <td id=\"T_b3497_row17_col1\" class=\"data row17 col1\" >0.01</td>\n",
       "      <td id=\"T_b3497_row17_col2\" class=\"data row17 col2\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row17_col3\" class=\"data row17 col3\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row17_col4\" class=\"data row17 col4\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row17_col5\" class=\"data row17 col5\" >0.01</td>\n",
       "      <td id=\"T_b3497_row17_col6\" class=\"data row17 col6\" >0.01</td>\n",
       "      <td id=\"T_b3497_row17_col7\" class=\"data row17 col7\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row17_col8\" class=\"data row17 col8\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row17_col9\" class=\"data row17 col9\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row17_col10\" class=\"data row17 col10\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row17_col11\" class=\"data row17 col11\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row17_col12\" class=\"data row17 col12\" >0.00</td>\n",
       "      <td id=\"T_b3497_row17_col13\" class=\"data row17 col13\" >0.00</td>\n",
       "      <td id=\"T_b3497_row17_col14\" class=\"data row17 col14\" >-0.06</td>\n",
       "      <td id=\"T_b3497_row17_col15\" class=\"data row17 col15\" >0.00</td>\n",
       "      <td id=\"T_b3497_row17_col16\" class=\"data row17 col16\" >0.00</td>\n",
       "      <td id=\"T_b3497_row17_col17\" class=\"data row17 col17\" >1.00</td>\n",
       "      <td id=\"T_b3497_row17_col18\" class=\"data row17 col18\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row17_col19\" class=\"data row17 col19\" >0.33</td>\n",
       "      <td id=\"T_b3497_row17_col20\" class=\"data row17 col20\" >0.00</td>\n",
       "      <td id=\"T_b3497_row17_col21\" class=\"data row17 col21\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row17_col22\" class=\"data row17 col22\" >0.01</td>\n",
       "      <td id=\"T_b3497_row17_col23\" class=\"data row17 col23\" >-0.32</td>\n",
       "      <td id=\"T_b3497_row17_col24\" class=\"data row17 col24\" >0.00</td>\n",
       "      <td id=\"T_b3497_row17_col25\" class=\"data row17 col25\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row17_col26\" class=\"data row17 col26\" >-0.14</td>\n",
       "      <td id=\"T_b3497_row17_col27\" class=\"data row17 col27\" >-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row18\" class=\"row_heading level0 row18\" >PRI_met</th>\n",
       "      <td id=\"T_b3497_row18_col0\" class=\"data row18 col0\" >0.09</td>\n",
       "      <td id=\"T_b3497_row18_col1\" class=\"data row18 col1\" >-0.06</td>\n",
       "      <td id=\"T_b3497_row18_col2\" class=\"data row18 col2\" >0.78</td>\n",
       "      <td id=\"T_b3497_row18_col3\" class=\"data row18 col3\" >-0.05</td>\n",
       "      <td id=\"T_b3497_row18_col4\" class=\"data row18 col4\" >0.14</td>\n",
       "      <td id=\"T_b3497_row18_col5\" class=\"data row18 col5\" >0.00</td>\n",
       "      <td id=\"T_b3497_row18_col6\" class=\"data row18 col6\" >-0.41</td>\n",
       "      <td id=\"T_b3497_row18_col7\" class=\"data row18 col7\" >0.15</td>\n",
       "      <td id=\"T_b3497_row18_col8\" class=\"data row18 col8\" >0.49</td>\n",
       "      <td id=\"T_b3497_row18_col9\" class=\"data row18 col9\" >0.00</td>\n",
       "      <td id=\"T_b3497_row18_col10\" class=\"data row18 col10\" >0.25</td>\n",
       "      <td id=\"T_b3497_row18_col11\" class=\"data row18 col11\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row18_col12\" class=\"data row18 col12\" >0.14</td>\n",
       "      <td id=\"T_b3497_row18_col13\" class=\"data row18 col13\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row18_col14\" class=\"data row18 col14\" >0.01</td>\n",
       "      <td id=\"T_b3497_row18_col15\" class=\"data row18 col15\" >0.11</td>\n",
       "      <td id=\"T_b3497_row18_col16\" class=\"data row18 col16\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row18_col17\" class=\"data row18 col17\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row18_col18\" class=\"data row18 col18\" >1.00</td>\n",
       "      <td id=\"T_b3497_row18_col19\" class=\"data row18 col19\" >0.00</td>\n",
       "      <td id=\"T_b3497_row18_col20\" class=\"data row18 col20\" >0.12</td>\n",
       "      <td id=\"T_b3497_row18_col21\" class=\"data row18 col21\" >0.61</td>\n",
       "      <td id=\"T_b3497_row18_col22\" class=\"data row18 col22\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row18_col23\" class=\"data row18 col23\" >0.00</td>\n",
       "      <td id=\"T_b3497_row18_col24\" class=\"data row18 col24\" >0.30</td>\n",
       "      <td id=\"T_b3497_row18_col25\" class=\"data row18 col25\" >0.00</td>\n",
       "      <td id=\"T_b3497_row18_col26\" class=\"data row18 col26\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row18_col27\" class=\"data row18 col27\" >-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row19\" class=\"row_heading level0 row19\" >PRI_met_phi</th>\n",
       "      <td id=\"T_b3497_row19_col0\" class=\"data row19 col0\" >0.00</td>\n",
       "      <td id=\"T_b3497_row19_col1\" class=\"data row19 col1\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row19_col2\" class=\"data row19 col2\" >0.01</td>\n",
       "      <td id=\"T_b3497_row19_col3\" class=\"data row19 col3\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row19_col4\" class=\"data row19 col4\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row19_col5\" class=\"data row19 col5\" >0.01</td>\n",
       "      <td id=\"T_b3497_row19_col6\" class=\"data row19 col6\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row19_col7\" class=\"data row19 col7\" >0.00</td>\n",
       "      <td id=\"T_b3497_row19_col8\" class=\"data row19 col8\" >0.00</td>\n",
       "      <td id=\"T_b3497_row19_col9\" class=\"data row19 col9\" >0.00</td>\n",
       "      <td id=\"T_b3497_row19_col10\" class=\"data row19 col10\" >0.00</td>\n",
       "      <td id=\"T_b3497_row19_col11\" class=\"data row19 col11\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row19_col12\" class=\"data row19 col12\" >0.00</td>\n",
       "      <td id=\"T_b3497_row19_col13\" class=\"data row19 col13\" >0.00</td>\n",
       "      <td id=\"T_b3497_row19_col14\" class=\"data row19 col14\" >0.17</td>\n",
       "      <td id=\"T_b3497_row19_col15\" class=\"data row19 col15\" >0.00</td>\n",
       "      <td id=\"T_b3497_row19_col16\" class=\"data row19 col16\" >0.00</td>\n",
       "      <td id=\"T_b3497_row19_col17\" class=\"data row19 col17\" >0.33</td>\n",
       "      <td id=\"T_b3497_row19_col18\" class=\"data row19 col18\" >0.00</td>\n",
       "      <td id=\"T_b3497_row19_col19\" class=\"data row19 col19\" >1.00</td>\n",
       "      <td id=\"T_b3497_row19_col20\" class=\"data row19 col20\" >0.00</td>\n",
       "      <td id=\"T_b3497_row19_col21\" class=\"data row19 col21\" >0.00</td>\n",
       "      <td id=\"T_b3497_row19_col22\" class=\"data row19 col22\" >0.01</td>\n",
       "      <td id=\"T_b3497_row19_col23\" class=\"data row19 col23\" >-0.32</td>\n",
       "      <td id=\"T_b3497_row19_col24\" class=\"data row19 col24\" >0.00</td>\n",
       "      <td id=\"T_b3497_row19_col25\" class=\"data row19 col25\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row19_col26\" class=\"data row19 col26\" >-0.13</td>\n",
       "      <td id=\"T_b3497_row19_col27\" class=\"data row19 col27\" >-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row20\" class=\"row_heading level0 row20\" >PRI_jet_num</th>\n",
       "      <td id=\"T_b3497_row20_col0\" class=\"data row20 col0\" >0.01</td>\n",
       "      <td id=\"T_b3497_row20_col1\" class=\"data row20 col1\" >0.05</td>\n",
       "      <td id=\"T_b3497_row20_col2\" class=\"data row20 col2\" >0.14</td>\n",
       "      <td id=\"T_b3497_row20_col3\" class=\"data row20 col3\" >-0.18</td>\n",
       "      <td id=\"T_b3497_row20_col4\" class=\"data row20 col4\" >-0.08</td>\n",
       "      <td id=\"T_b3497_row20_col5\" class=\"data row20 col5\" >0.12</td>\n",
       "      <td id=\"T_b3497_row20_col6\" class=\"data row20 col6\" >-0.11</td>\n",
       "      <td id=\"T_b3497_row20_col7\" class=\"data row20 col7\" >0.60</td>\n",
       "      <td id=\"T_b3497_row20_col8\" class=\"data row20 col8\" >0.40</td>\n",
       "      <td id=\"T_b3497_row20_col9\" class=\"data row20 col9\" >0.06</td>\n",
       "      <td id=\"T_b3497_row20_col10\" class=\"data row20 col10\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row20_col11\" class=\"data row20 col11\" >-0.13</td>\n",
       "      <td id=\"T_b3497_row20_col12\" class=\"data row20 col12\" >0.03</td>\n",
       "      <td id=\"T_b3497_row20_col13\" class=\"data row20 col13\" >0.00</td>\n",
       "      <td id=\"T_b3497_row20_col14\" class=\"data row20 col14\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row20_col15\" class=\"data row20 col15\" >0.08</td>\n",
       "      <td id=\"T_b3497_row20_col16\" class=\"data row20 col16\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row20_col17\" class=\"data row20 col17\" >0.00</td>\n",
       "      <td id=\"T_b3497_row20_col18\" class=\"data row20 col18\" >0.12</td>\n",
       "      <td id=\"T_b3497_row20_col19\" class=\"data row20 col19\" >0.00</td>\n",
       "      <td id=\"T_b3497_row20_col20\" class=\"data row20 col20\" >1.00</td>\n",
       "      <td id=\"T_b3497_row20_col21\" class=\"data row20 col21\" >0.17</td>\n",
       "      <td id=\"T_b3497_row20_col22\" class=\"data row20 col22\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row20_col23\" class=\"data row20 col23\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row20_col24\" class=\"data row20 col24\" >0.29</td>\n",
       "      <td id=\"T_b3497_row20_col25\" class=\"data row20 col25\" >0.00</td>\n",
       "      <td id=\"T_b3497_row20_col26\" class=\"data row20 col26\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row20_col27\" class=\"data row20 col27\" >-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row21\" class=\"row_heading level0 row21\" >PRI_jet_leading_pt</th>\n",
       "      <td id=\"T_b3497_row21_col0\" class=\"data row21 col0\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row21_col1\" class=\"data row21 col1\" >-0.11</td>\n",
       "      <td id=\"T_b3497_row21_col2\" class=\"data row21 col2\" >0.75</td>\n",
       "      <td id=\"T_b3497_row21_col3\" class=\"data row21 col3\" >-0.05</td>\n",
       "      <td id=\"T_b3497_row21_col4\" class=\"data row21 col4\" >0.28</td>\n",
       "      <td id=\"T_b3497_row21_col5\" class=\"data row21 col5\" >-0.02</td>\n",
       "      <td id=\"T_b3497_row21_col6\" class=\"data row21 col6\" >-0.48</td>\n",
       "      <td id=\"T_b3497_row21_col7\" class=\"data row21 col7\" >0.19</td>\n",
       "      <td id=\"T_b3497_row21_col8\" class=\"data row21 col8\" >0.88</td>\n",
       "      <td id=\"T_b3497_row21_col9\" class=\"data row21 col9\" >0.07</td>\n",
       "      <td id=\"T_b3497_row21_col10\" class=\"data row21 col10\" >0.21</td>\n",
       "      <td id=\"T_b3497_row21_col11\" class=\"data row21 col11\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row21_col12\" class=\"data row21 col12\" >0.35</td>\n",
       "      <td id=\"T_b3497_row21_col13\" class=\"data row21 col13\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row21_col14\" class=\"data row21 col14\" >0.01</td>\n",
       "      <td id=\"T_b3497_row21_col15\" class=\"data row21 col15\" >0.30</td>\n",
       "      <td id=\"T_b3497_row21_col16\" class=\"data row21 col16\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row21_col17\" class=\"data row21 col17\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row21_col18\" class=\"data row21 col18\" >0.61</td>\n",
       "      <td id=\"T_b3497_row21_col19\" class=\"data row21 col19\" >0.00</td>\n",
       "      <td id=\"T_b3497_row21_col20\" class=\"data row21 col20\" >0.17</td>\n",
       "      <td id=\"T_b3497_row21_col21\" class=\"data row21 col21\" >1.00</td>\n",
       "      <td id=\"T_b3497_row21_col22\" class=\"data row21 col22\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row21_col23\" class=\"data row21 col23\" >0.00</td>\n",
       "      <td id=\"T_b3497_row21_col24\" class=\"data row21 col24\" >0.57</td>\n",
       "      <td id=\"T_b3497_row21_col25\" class=\"data row21 col25\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row21_col26\" class=\"data row21 col26\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row21_col27\" class=\"data row21 col27\" >-0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row22\" class=\"row_heading level0 row22\" >PRI_jet_leading_eta</th>\n",
       "      <td id=\"T_b3497_row22_col0\" class=\"data row22 col0\" >0.00</td>\n",
       "      <td id=\"T_b3497_row22_col1\" class=\"data row22 col1\" >0.00</td>\n",
       "      <td id=\"T_b3497_row22_col2\" class=\"data row22 col2\" >0.00</td>\n",
       "      <td id=\"T_b3497_row22_col3\" class=\"data row22 col3\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row22_col4\" class=\"data row22 col4\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row22_col5\" class=\"data row22 col5\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row22_col6\" class=\"data row22 col6\" >0.01</td>\n",
       "      <td id=\"T_b3497_row22_col7\" class=\"data row22 col7\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row22_col8\" class=\"data row22 col8\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row22_col9\" class=\"data row22 col9\" >0.00</td>\n",
       "      <td id=\"T_b3497_row22_col10\" class=\"data row22 col10\" >0.01</td>\n",
       "      <td id=\"T_b3497_row22_col11\" class=\"data row22 col11\" >0.00</td>\n",
       "      <td id=\"T_b3497_row22_col12\" class=\"data row22 col12\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row22_col13\" class=\"data row22 col13\" >0.19</td>\n",
       "      <td id=\"T_b3497_row22_col14\" class=\"data row22 col14\" >0.01</td>\n",
       "      <td id=\"T_b3497_row22_col15\" class=\"data row22 col15\" >0.00</td>\n",
       "      <td id=\"T_b3497_row22_col16\" class=\"data row22 col16\" >0.21</td>\n",
       "      <td id=\"T_b3497_row22_col17\" class=\"data row22 col17\" >0.01</td>\n",
       "      <td id=\"T_b3497_row22_col18\" class=\"data row22 col18\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row22_col19\" class=\"data row22 col19\" >0.01</td>\n",
       "      <td id=\"T_b3497_row22_col20\" class=\"data row22 col20\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row22_col21\" class=\"data row22 col21\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row22_col22\" class=\"data row22 col22\" >1.00</td>\n",
       "      <td id=\"T_b3497_row22_col23\" class=\"data row22 col23\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row22_col24\" class=\"data row22 col24\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row22_col25\" class=\"data row22 col25\" >-0.25</td>\n",
       "      <td id=\"T_b3497_row22_col26\" class=\"data row22 col26\" >0.00</td>\n",
       "      <td id=\"T_b3497_row22_col27\" class=\"data row22 col27\" >0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row23\" class=\"row_heading level0 row23\" >PRI_jet_leading_phi</th>\n",
       "      <td id=\"T_b3497_row23_col0\" class=\"data row23 col0\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row23_col1\" class=\"data row23 col1\" >0.00</td>\n",
       "      <td id=\"T_b3497_row23_col2\" class=\"data row23 col2\" >0.00</td>\n",
       "      <td id=\"T_b3497_row23_col3\" class=\"data row23 col3\" >0.00</td>\n",
       "      <td id=\"T_b3497_row23_col4\" class=\"data row23 col4\" >0.00</td>\n",
       "      <td id=\"T_b3497_row23_col5\" class=\"data row23 col5\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row23_col6\" class=\"data row23 col6\" >0.00</td>\n",
       "      <td id=\"T_b3497_row23_col7\" class=\"data row23 col7\" >0.00</td>\n",
       "      <td id=\"T_b3497_row23_col8\" class=\"data row23 col8\" >0.00</td>\n",
       "      <td id=\"T_b3497_row23_col9\" class=\"data row23 col9\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row23_col10\" class=\"data row23 col10\" >0.00</td>\n",
       "      <td id=\"T_b3497_row23_col11\" class=\"data row23 col11\" >0.00</td>\n",
       "      <td id=\"T_b3497_row23_col12\" class=\"data row23 col12\" >0.00</td>\n",
       "      <td id=\"T_b3497_row23_col13\" class=\"data row23 col13\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row23_col14\" class=\"data row23 col14\" >-0.22</td>\n",
       "      <td id=\"T_b3497_row23_col15\" class=\"data row23 col15\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row23_col16\" class=\"data row23 col16\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row23_col17\" class=\"data row23 col17\" >-0.32</td>\n",
       "      <td id=\"T_b3497_row23_col18\" class=\"data row23 col18\" >0.00</td>\n",
       "      <td id=\"T_b3497_row23_col19\" class=\"data row23 col19\" >-0.32</td>\n",
       "      <td id=\"T_b3497_row23_col20\" class=\"data row23 col20\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row23_col21\" class=\"data row23 col21\" >0.00</td>\n",
       "      <td id=\"T_b3497_row23_col22\" class=\"data row23 col22\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row23_col23\" class=\"data row23 col23\" >1.00</td>\n",
       "      <td id=\"T_b3497_row23_col24\" class=\"data row23 col24\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row23_col25\" class=\"data row23 col25\" >0.01</td>\n",
       "      <td id=\"T_b3497_row23_col26\" class=\"data row23 col26\" >-0.06</td>\n",
       "      <td id=\"T_b3497_row23_col27\" class=\"data row23 col27\" >-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row24\" class=\"row_heading level0 row24\" >PRI_jet_subleading_pt</th>\n",
       "      <td id=\"T_b3497_row24_col0\" class=\"data row24 col0\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row24_col1\" class=\"data row24 col1\" >-0.03</td>\n",
       "      <td id=\"T_b3497_row24_col2\" class=\"data row24 col2\" >0.36</td>\n",
       "      <td id=\"T_b3497_row24_col3\" class=\"data row24 col3\" >-0.09</td>\n",
       "      <td id=\"T_b3497_row24_col4\" class=\"data row24 col4\" >0.23</td>\n",
       "      <td id=\"T_b3497_row24_col5\" class=\"data row24 col5\" >0.01</td>\n",
       "      <td id=\"T_b3497_row24_col6\" class=\"data row24 col6\" >-0.24</td>\n",
       "      <td id=\"T_b3497_row24_col7\" class=\"data row24 col7\" >0.33</td>\n",
       "      <td id=\"T_b3497_row24_col8\" class=\"data row24 col8\" >0.73</td>\n",
       "      <td id=\"T_b3497_row24_col9\" class=\"data row24 col9\" >0.05</td>\n",
       "      <td id=\"T_b3497_row24_col10\" class=\"data row24 col10\" >0.08</td>\n",
       "      <td id=\"T_b3497_row24_col11\" class=\"data row24 col11\" >-0.03</td>\n",
       "      <td id=\"T_b3497_row24_col12\" class=\"data row24 col12\" >0.15</td>\n",
       "      <td id=\"T_b3497_row24_col13\" class=\"data row24 col13\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row24_col14\" class=\"data row24 col14\" >0.00</td>\n",
       "      <td id=\"T_b3497_row24_col15\" class=\"data row24 col15\" >0.15</td>\n",
       "      <td id=\"T_b3497_row24_col16\" class=\"data row24 col16\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row24_col17\" class=\"data row24 col17\" >0.00</td>\n",
       "      <td id=\"T_b3497_row24_col18\" class=\"data row24 col18\" >0.30</td>\n",
       "      <td id=\"T_b3497_row24_col19\" class=\"data row24 col19\" >0.00</td>\n",
       "      <td id=\"T_b3497_row24_col20\" class=\"data row24 col20\" >0.29</td>\n",
       "      <td id=\"T_b3497_row24_col21\" class=\"data row24 col21\" >0.57</td>\n",
       "      <td id=\"T_b3497_row24_col22\" class=\"data row24 col22\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row24_col23\" class=\"data row24 col23\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row24_col24\" class=\"data row24 col24\" >1.00</td>\n",
       "      <td id=\"T_b3497_row24_col25\" class=\"data row24 col25\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row24_col26\" class=\"data row24 col26\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row24_col27\" class=\"data row24 col27\" >-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row25\" class=\"row_heading level0 row25\" >PRI_jet_subleading_eta</th>\n",
       "      <td id=\"T_b3497_row25_col0\" class=\"data row25 col0\" >0.01</td>\n",
       "      <td id=\"T_b3497_row25_col1\" class=\"data row25 col1\" >0.00</td>\n",
       "      <td id=\"T_b3497_row25_col2\" class=\"data row25 col2\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row25_col3\" class=\"data row25 col3\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row25_col4\" class=\"data row25 col4\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row25_col5\" class=\"data row25 col5\" >0.00</td>\n",
       "      <td id=\"T_b3497_row25_col6\" class=\"data row25 col6\" >0.01</td>\n",
       "      <td id=\"T_b3497_row25_col7\" class=\"data row25 col7\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row25_col8\" class=\"data row25 col8\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row25_col9\" class=\"data row25 col9\" >0.00</td>\n",
       "      <td id=\"T_b3497_row25_col10\" class=\"data row25 col10\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row25_col11\" class=\"data row25 col11\" >0.00</td>\n",
       "      <td id=\"T_b3497_row25_col12\" class=\"data row25 col12\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row25_col13\" class=\"data row25 col13\" >0.15</td>\n",
       "      <td id=\"T_b3497_row25_col14\" class=\"data row25 col14\" >0.00</td>\n",
       "      <td id=\"T_b3497_row25_col15\" class=\"data row25 col15\" >0.00</td>\n",
       "      <td id=\"T_b3497_row25_col16\" class=\"data row25 col16\" >0.16</td>\n",
       "      <td id=\"T_b3497_row25_col17\" class=\"data row25 col17\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row25_col18\" class=\"data row25 col18\" >0.00</td>\n",
       "      <td id=\"T_b3497_row25_col19\" class=\"data row25 col19\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row25_col20\" class=\"data row25 col20\" >0.00</td>\n",
       "      <td id=\"T_b3497_row25_col21\" class=\"data row25 col21\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row25_col22\" class=\"data row25 col22\" >-0.25</td>\n",
       "      <td id=\"T_b3497_row25_col23\" class=\"data row25 col23\" >0.01</td>\n",
       "      <td id=\"T_b3497_row25_col24\" class=\"data row25 col24\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row25_col25\" class=\"data row25 col25\" >1.00</td>\n",
       "      <td id=\"T_b3497_row25_col26\" class=\"data row25 col26\" >0.00</td>\n",
       "      <td id=\"T_b3497_row25_col27\" class=\"data row25 col27\" >-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row26\" class=\"row_heading level0 row26\" >PRI_jet_subleading_phi</th>\n",
       "      <td id=\"T_b3497_row26_col0\" class=\"data row26 col0\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row26_col1\" class=\"data row26 col1\" >0.01</td>\n",
       "      <td id=\"T_b3497_row26_col2\" class=\"data row26 col2\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row26_col3\" class=\"data row26 col3\" >0.00</td>\n",
       "      <td id=\"T_b3497_row26_col4\" class=\"data row26 col4\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row26_col5\" class=\"data row26 col5\" >0.00</td>\n",
       "      <td id=\"T_b3497_row26_col6\" class=\"data row26 col6\" >0.01</td>\n",
       "      <td id=\"T_b3497_row26_col7\" class=\"data row26 col7\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row26_col8\" class=\"data row26 col8\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row26_col9\" class=\"data row26 col9\" >0.00</td>\n",
       "      <td id=\"T_b3497_row26_col10\" class=\"data row26 col10\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row26_col11\" class=\"data row26 col11\" >0.00</td>\n",
       "      <td id=\"T_b3497_row26_col12\" class=\"data row26 col12\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row26_col13\" class=\"data row26 col13\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row26_col14\" class=\"data row26 col14\" >-0.11</td>\n",
       "      <td id=\"T_b3497_row26_col15\" class=\"data row26 col15\" >0.00</td>\n",
       "      <td id=\"T_b3497_row26_col16\" class=\"data row26 col16\" >0.00</td>\n",
       "      <td id=\"T_b3497_row26_col17\" class=\"data row26 col17\" >-0.14</td>\n",
       "      <td id=\"T_b3497_row26_col18\" class=\"data row26 col18\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row26_col19\" class=\"data row26 col19\" >-0.13</td>\n",
       "      <td id=\"T_b3497_row26_col20\" class=\"data row26 col20\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row26_col21\" class=\"data row26 col21\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row26_col22\" class=\"data row26 col22\" >0.00</td>\n",
       "      <td id=\"T_b3497_row26_col23\" class=\"data row26 col23\" >-0.06</td>\n",
       "      <td id=\"T_b3497_row26_col24\" class=\"data row26 col24\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row26_col25\" class=\"data row26 col25\" >0.00</td>\n",
       "      <td id=\"T_b3497_row26_col26\" class=\"data row26 col26\" >1.00</td>\n",
       "      <td id=\"T_b3497_row26_col27\" class=\"data row26 col27\" >0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b3497_level0_row27\" class=\"row_heading level0 row27\" >Weight</th>\n",
       "      <td id=\"T_b3497_row27_col0\" class=\"data row27 col0\" >0.17</td>\n",
       "      <td id=\"T_b3497_row27_col1\" class=\"data row27 col1\" >0.35</td>\n",
       "      <td id=\"T_b3497_row27_col2\" class=\"data row27 col2\" >-0.20</td>\n",
       "      <td id=\"T_b3497_row27_col3\" class=\"data row27 col3\" >-0.29</td>\n",
       "      <td id=\"T_b3497_row27_col4\" class=\"data row27 col4\" >-0.28</td>\n",
       "      <td id=\"T_b3497_row27_col5\" class=\"data row27 col5\" >0.25</td>\n",
       "      <td id=\"T_b3497_row27_col6\" class=\"data row27 col6\" >0.23</td>\n",
       "      <td id=\"T_b3497_row27_col7\" class=\"data row27 col7\" >-0.03</td>\n",
       "      <td id=\"T_b3497_row27_col8\" class=\"data row27 col8\" >-0.14</td>\n",
       "      <td id=\"T_b3497_row27_col9\" class=\"data row27 col9\" >0.24</td>\n",
       "      <td id=\"T_b3497_row27_col10\" class=\"data row27 col10\" >-0.30</td>\n",
       "      <td id=\"T_b3497_row27_col11\" class=\"data row27 col11\" >-0.25</td>\n",
       "      <td id=\"T_b3497_row27_col12\" class=\"data row27 col12\" >-0.18</td>\n",
       "      <td id=\"T_b3497_row27_col13\" class=\"data row27 col13\" >0.00</td>\n",
       "      <td id=\"T_b3497_row27_col14\" class=\"data row27 col14\" >0.00</td>\n",
       "      <td id=\"T_b3497_row27_col15\" class=\"data row27 col15\" >0.12</td>\n",
       "      <td id=\"T_b3497_row27_col16\" class=\"data row27 col16\" >0.01</td>\n",
       "      <td id=\"T_b3497_row27_col17\" class=\"data row27 col17\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row27_col18\" class=\"data row27 col18\" >-0.13</td>\n",
       "      <td id=\"T_b3497_row27_col19\" class=\"data row27 col19\" >-0.01</td>\n",
       "      <td id=\"T_b3497_row27_col20\" class=\"data row27 col20\" >-0.05</td>\n",
       "      <td id=\"T_b3497_row27_col21\" class=\"data row27 col21\" >-0.16</td>\n",
       "      <td id=\"T_b3497_row27_col22\" class=\"data row27 col22\" >0.00</td>\n",
       "      <td id=\"T_b3497_row27_col23\" class=\"data row27 col23\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row27_col24\" class=\"data row27 col24\" >-0.11</td>\n",
       "      <td id=\"T_b3497_row27_col25\" class=\"data row27 col25\" >-0.00</td>\n",
       "      <td id=\"T_b3497_row27_col26\" class=\"data row27 col26\" >0.01</td>\n",
       "      <td id=\"T_b3497_row27_col27\" class=\"data row27 col27\" >1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x198993ddd90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation for Higgs Dataset\n",
    "corr = higgs_train_df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_higgs, X_test_higgs, y_train_higgs, y_test_higgs = le_split(X_higgs, y_higgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cover Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = range(50, 400, 50)\n",
    "max_depth = range(1, 11, 2)\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "\n",
    "param_grid_cov = dict(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate)\n",
    "\n",
    "model_cov = xgb.XGBClassifier(n_estimators = 200, learning_rate = 0.1, nthread=-1)\n",
    "\n",
    "model_cov = train_model(model_cov, X_train_cov, y_train_cov, grid=True, params= param_grid_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this if best parameters are known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cov = xgb.XGBClassifier(n_estimators = 350, learning_rate = 0.3, max_depth = 9, nthread=-1) #best parameters shown\n",
    "\n",
    "model_cov = train_model(model_cov, X_train_cov, y_train_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Cover Type Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9760624399453819\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      8410\n",
      "           1       0.93      0.92      0.92      8476\n",
      "           2       0.99      0.99      0.99      8399\n",
      "           3       1.00      1.00      1.00      8414\n",
      "           4       0.99      1.00      0.99      8463\n",
      "           5       0.99      1.00      0.99      8640\n",
      "           6       0.99      1.00      1.00      8519\n",
      "\n",
      "    accuracy                           0.98     59321\n",
      "   macro avg       0.98      0.98      0.98     59321\n",
      "weighted avg       0.98      0.98      0.98     59321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_cov = evaluate_model(model_cov, X_test_cov, y_test_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code adds some generated data to the HELOC dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adds synthetic data to the HELOC dataset to compensate for the small training dataset\n",
    "oversample = SMOTE()\n",
    "X_train_heloc, y_train_heloc = oversample.fit_resample(X_train_heloc, y_train_heloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 210 candidates, totalling 2100 fits\n",
      "{'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 350}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = range(50, 400, 50)\n",
    "max_depth = range(1, 11, 2)\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "\n",
    "param_grid_heloc = dict(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate)\n",
    "\n",
    "model_heloc = xgb.XGBClassifier()\n",
    "\n",
    "model_heloc = train_model(model_heloc, X_train_heloc, y_train_heloc, grid=True, params= param_grid_heloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this if the best parameters are known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_heloc = xgb.XGBClassifier(learning_rate = 0.1, max_depth= 1, n_estimators= 350)\n",
    "\n",
    "model_heloc = train_model(model_heloc, X_train_heloc, y_train_heloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the HELOC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6914414414414415\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       285\n",
      "           1       0.56      0.61      0.59       159\n",
      "\n",
      "    accuracy                           0.69       444\n",
      "   macro avg       0.67      0.67      0.67       444\n",
      "weighted avg       0.70      0.69      0.69       444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_heloc = evaluate_model(model_heloc, X_test_heloc, y_test_heloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 210 candidates, totalling 1050 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {color: black;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, nthread=-1,\n",
       "                                     num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
       "                         &#x27;max_depth&#x27;: range(1, 11, 2),\n",
       "                         &#x27;n_estimators&#x27;: range(50, 400, 50)},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, nthread=-1,\n",
       "                                     num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
       "                         &#x27;max_depth&#x27;: range(1, 11, 2),\n",
       "                         &#x27;n_estimators&#x27;: range(50, 400, 50)},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, nthread=-1,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, nthread=-1,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, nthread=-1,\n",
       "                                     num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
       "                         'max_depth': range(1, 11, 2),\n",
       "                         'n_estimators': range(50, 400, 50)},\n",
       "             scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_higgs = xgb.XGBClassifier(nthread=-1)\n",
    "\n",
    "n_estimators = range(50, 400, 50) # tune number of trees\n",
    "max_depth = range(1, 11, 2) # tune size of decision trees\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3] # tune the learning rate\n",
    "\n",
    "param_grid_higgs = dict(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate)\n",
    "\n",
    "grid_search_higgs = GridSearchCV(model_higgs, param_grid_higgs, scoring=\"accuracy\", n_jobs=-1, cv=5, verbose=5)\n",
    "grid_search_higgs.fit(X_train_higgs, y_train_higgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 250}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_higgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8432330564668109\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      7679\n",
      "           1       0.83      0.83      0.83      6648\n",
      "\n",
      "    accuracy                           0.84     14327\n",
      "   macro avg       0.84      0.84      0.84     14327\n",
      "weighted avg       0.84      0.84      0.84     14327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model_higgs = grid_search_higgs.best_estimator_\n",
    "\n",
    "#model_higgs = xgb.XGBClassifier(eta = 0.2, max_depth = 6, gamma = 5)\n",
    "model_higgs = xgb.XGBClassifier(learning_rate = 0.1, max_depth = 5, n_estimators = 250)\n",
    "model_higgs.fit(X_train_higgs, y_train_higgs)\n",
    "\n",
    "predictions_higgs = model_higgs.predict(X_test_higgs)\n",
    "\n",
    "#Calculating accuracy\n",
    "accuracy_higgs = accuracy_score(y_test_higgs, predictions_higgs)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_higgs)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_higgs, predictions_higgs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_cov = pd.read_csv('covtype_test.csv')\n",
    "y_final_heloc = pd.read_csv('heloc_test.csv')\n",
    "y_final_higgs = pd.read_csv('higgs_test.csv').drop(['EventId', 'Weight', 'PRI_jet_all_pt', \"PRI_met_sumet\", 'DER_mass_vis' ], axis=1)\n",
    "\n",
    "final_preds_cov = model_cov.predict(y_final_cov)+1\n",
    "final_preds_heloc = model_heloc.predict(y_final_heloc)\n",
    "final_preds_higgs = model_higgs.predict(y_final_higgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_cov = pd.read_csv('covtype_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_cov.predict(y_final_cov.to_numpy())\n",
    "final_preds_cov = model_cov.predict(y_final_cov.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cover Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.35809 | train_accuracy: 0.66816 | valid_accuracy: 0.66982 |  0:00:25s\n",
      "epoch 1  | loss: 0.80334 | train_accuracy: 0.69682 | valid_accuracy: 0.69934 |  0:00:49s\n",
      "epoch 2  | loss: 0.74155 | train_accuracy: 0.71568 | valid_accuracy: 0.7156  |  0:01:13s\n",
      "epoch 3  | loss: 0.71294 | train_accuracy: 0.71779 | valid_accuracy: 0.72197 |  0:01:38s\n",
      "epoch 4  | loss: 0.69376 | train_accuracy: 0.72141 | valid_accuracy: 0.72283 |  0:02:03s\n",
      "epoch 5  | loss: 0.67787 | train_accuracy: 0.72851 | valid_accuracy: 0.72911 |  0:02:27s\n",
      "epoch 6  | loss: 0.66957 | train_accuracy: 0.73221 | valid_accuracy: 0.73298 |  0:02:51s\n",
      "epoch 7  | loss: 0.66367 | train_accuracy: 0.73511 | valid_accuracy: 0.73505 |  0:03:16s\n",
      "epoch 8  | loss: 0.65089 | train_accuracy: 0.7386  | valid_accuracy: 0.73918 |  0:03:40s\n",
      "epoch 9  | loss: 0.64806 | train_accuracy: 0.74034 | valid_accuracy: 0.73935 |  0:04:04s\n",
      "epoch 10 | loss: 0.64041 | train_accuracy: 0.73929 | valid_accuracy: 0.74056 |  0:04:28s\n",
      "epoch 11 | loss: 0.63506 | train_accuracy: 0.74662 | valid_accuracy: 0.74477 |  0:04:53s\n",
      "epoch 12 | loss: 0.63143 | train_accuracy: 0.74462 | valid_accuracy: 0.74047 |  0:05:17s\n",
      "epoch 13 | loss: 0.6271  | train_accuracy: 0.74994 | valid_accuracy: 0.744   |  0:05:41s\n",
      "epoch 14 | loss: 0.62217 | train_accuracy: 0.74761 | valid_accuracy: 0.74572 |  0:06:05s\n",
      "epoch 15 | loss: 0.61962 | train_accuracy: 0.75404 | valid_accuracy: 0.75407 |  0:06:30s\n",
      "epoch 16 | loss: 0.61401 | train_accuracy: 0.75577 | valid_accuracy: 0.75191 |  0:06:54s\n",
      "epoch 17 | loss: 0.61544 | train_accuracy: 0.7543  | valid_accuracy: 0.75432 |  0:07:18s\n",
      "epoch 18 | loss: 0.61318 | train_accuracy: 0.75349 | valid_accuracy: 0.7477  |  0:07:43s\n",
      "epoch 19 | loss: 0.6066  | train_accuracy: 0.75792 | valid_accuracy: 0.74882 |  0:08:07s\n",
      "epoch 20 | loss: 0.60472 | train_accuracy: 0.75893 | valid_accuracy: 0.7551  |  0:08:31s\n",
      "epoch 21 | loss: 0.6011  | train_accuracy: 0.7596  | valid_accuracy: 0.75234 |  0:08:55s\n",
      "epoch 22 | loss: 0.59792 | train_accuracy: 0.75796 | valid_accuracy: 0.74864 |  0:09:19s\n",
      "epoch 23 | loss: 0.59508 | train_accuracy: 0.75809 | valid_accuracy: 0.75088 |  0:09:44s\n",
      "epoch 24 | loss: 0.59284 | train_accuracy: 0.76056 | valid_accuracy: 0.75183 |  0:10:08s\n",
      "epoch 25 | loss: 0.59581 | train_accuracy: 0.75633 | valid_accuracy: 0.74744 |  0:10:32s\n",
      "epoch 26 | loss: 0.5903  | train_accuracy: 0.75889 | valid_accuracy: 0.75191 |  0:10:57s\n",
      "epoch 27 | loss: 0.58973 | train_accuracy: 0.76472 | valid_accuracy: 0.75906 |  0:11:21s\n",
      "epoch 28 | loss: 0.58625 | train_accuracy: 0.76269 | valid_accuracy: 0.75828 |  0:11:45s\n",
      "epoch 29 | loss: 0.58663 | train_accuracy: 0.76674 | valid_accuracy: 0.76052 |  0:12:09s\n",
      "epoch 30 | loss: 0.58219 | train_accuracy: 0.76254 | valid_accuracy: 0.75699 |  0:12:34s\n",
      "epoch 31 | loss: 0.58195 | train_accuracy: 0.77016 | valid_accuracy: 0.76069 |  0:12:58s\n",
      "epoch 32 | loss: 0.58131 | train_accuracy: 0.76687 | valid_accuracy: 0.75725 |  0:13:22s\n",
      "epoch 33 | loss: 0.58001 | train_accuracy: 0.76949 | valid_accuracy: 0.76052 |  0:13:47s\n",
      "epoch 34 | loss: 0.57848 | train_accuracy: 0.77345 | valid_accuracy: 0.76405 |  0:14:11s\n",
      "epoch 35 | loss: 0.57587 | train_accuracy: 0.77096 | valid_accuracy: 0.76327 |  0:14:36s\n",
      "epoch 36 | loss: 0.57481 | train_accuracy: 0.76751 | valid_accuracy: 0.7551  |  0:15:00s\n",
      "epoch 37 | loss: 0.57475 | train_accuracy: 0.77121 | valid_accuracy: 0.76026 |  0:15:24s\n",
      "epoch 38 | loss: 0.57558 | train_accuracy: 0.77608 | valid_accuracy: 0.76551 |  0:15:49s\n",
      "epoch 39 | loss: 0.56964 | train_accuracy: 0.77304 | valid_accuracy: 0.76508 |  0:16:14s\n",
      "epoch 40 | loss: 0.56802 | train_accuracy: 0.77614 | valid_accuracy: 0.76525 |  0:16:38s\n",
      "epoch 41 | loss: 0.56631 | train_accuracy: 0.77849 | valid_accuracy: 0.76758 |  0:17:02s\n",
      "epoch 42 | loss: 0.56868 | train_accuracy: 0.77392 | valid_accuracy: 0.76465 |  0:17:27s\n",
      "epoch 43 | loss: 0.56737 | train_accuracy: 0.77644 | valid_accuracy: 0.76809 |  0:17:51s\n",
      "epoch 44 | loss: 0.5627  | train_accuracy: 0.77599 | valid_accuracy: 0.76577 |  0:18:16s\n",
      "epoch 45 | loss: 0.56342 | train_accuracy: 0.78081 | valid_accuracy: 0.76672 |  0:18:40s\n",
      "epoch 46 | loss: 0.56397 | train_accuracy: 0.77844 | valid_accuracy: 0.76284 |  0:19:05s\n",
      "epoch 47 | loss: 0.56202 | train_accuracy: 0.78038 | valid_accuracy: 0.76904 |  0:19:29s\n",
      "epoch 48 | loss: 0.55873 | train_accuracy: 0.78449 | valid_accuracy: 0.77033 |  0:19:54s\n",
      "epoch 49 | loss: 0.56007 | train_accuracy: 0.78552 | valid_accuracy: 0.77076 |  0:20:20s\n",
      "epoch 50 | loss: 0.55769 | train_accuracy: 0.78386 | valid_accuracy: 0.77377 |  0:20:45s\n",
      "epoch 51 | loss: 0.55558 | train_accuracy: 0.78591 | valid_accuracy: 0.77196 |  0:21:10s\n",
      "epoch 52 | loss: 0.55832 | train_accuracy: 0.78586 | valid_accuracy: 0.77326 |  0:21:36s\n",
      "epoch 53 | loss: 0.55664 | train_accuracy: 0.7861  | valid_accuracy: 0.77248 |  0:22:00s\n",
      "epoch 54 | loss: 0.5561  | train_accuracy: 0.78614 | valid_accuracy: 0.77326 |  0:22:25s\n",
      "epoch 55 | loss: 0.55393 | train_accuracy: 0.78933 | valid_accuracy: 0.77558 |  0:22:49s\n",
      "epoch 56 | loss: 0.55685 | train_accuracy: 0.78879 | valid_accuracy: 0.77429 |  0:23:14s\n",
      "epoch 57 | loss: 0.55383 | train_accuracy: 0.78883 | valid_accuracy: 0.77334 |  0:23:38s\n",
      "epoch 58 | loss: 0.55108 | train_accuracy: 0.78997 | valid_accuracy: 0.77678 |  0:24:03s\n",
      "epoch 59 | loss: 0.55208 | train_accuracy: 0.78944 | valid_accuracy: 0.77816 |  0:24:27s\n",
      "epoch 60 | loss: 0.54804 | train_accuracy: 0.79036 | valid_accuracy: 0.77635 |  0:24:52s\n",
      "epoch 61 | loss: 0.54941 | train_accuracy: 0.79206 | valid_accuracy: 0.77928 |  0:25:16s\n",
      "epoch 62 | loss: 0.54692 | train_accuracy: 0.78479 | valid_accuracy: 0.76981 |  0:25:40s\n",
      "epoch 63 | loss: 0.5472  | train_accuracy: 0.79118 | valid_accuracy: 0.77566 |  0:26:05s\n",
      "epoch 64 | loss: 0.54824 | train_accuracy: 0.79314 | valid_accuracy: 0.7785  |  0:26:29s\n",
      "epoch 65 | loss: 0.54758 | train_accuracy: 0.79058 | valid_accuracy: 0.77678 |  0:26:54s\n",
      "epoch 66 | loss: 0.54673 | train_accuracy: 0.79305 | valid_accuracy: 0.77868 |  0:27:18s\n",
      "epoch 67 | loss: 0.54255 | train_accuracy: 0.7935  | valid_accuracy: 0.77825 |  0:27:42s\n",
      "epoch 68 | loss: 0.54397 | train_accuracy: 0.7923  | valid_accuracy: 0.77532 |  0:28:07s\n",
      "epoch 69 | loss: 0.54551 | train_accuracy: 0.79154 | valid_accuracy: 0.77653 |  0:28:31s\n",
      "epoch 70 | loss: 0.54366 | train_accuracy: 0.79288 | valid_accuracy: 0.77988 |  0:28:56s\n",
      "epoch 71 | loss: 0.54383 | train_accuracy: 0.79006 | valid_accuracy: 0.77558 |  0:29:20s\n",
      "epoch 72 | loss: 0.54447 | train_accuracy: 0.7954  | valid_accuracy: 0.78117 |  0:29:44s\n",
      "epoch 73 | loss: 0.53847 | train_accuracy: 0.79305 | valid_accuracy: 0.77696 |  0:30:09s\n",
      "epoch 74 | loss: 0.54102 | train_accuracy: 0.79542 | valid_accuracy: 0.77945 |  0:30:33s\n",
      "epoch 75 | loss: 0.54023 | train_accuracy: 0.79733 | valid_accuracy: 0.77902 |  0:30:58s\n",
      "epoch 76 | loss: 0.53901 | train_accuracy: 0.79677 | valid_accuracy: 0.7798  |  0:31:22s\n",
      "epoch 77 | loss: 0.53806 | train_accuracy: 0.79722 | valid_accuracy: 0.77902 |  0:31:47s\n",
      "epoch 78 | loss: 0.53901 | train_accuracy: 0.7966  | valid_accuracy: 0.78238 |  0:32:11s\n",
      "epoch 79 | loss: 0.5384  | train_accuracy: 0.79785 | valid_accuracy: 0.78332 |  0:32:35s\n",
      "epoch 80 | loss: 0.53666 | train_accuracy: 0.79849 | valid_accuracy: 0.78289 |  0:33:00s\n",
      "epoch 81 | loss: 0.53869 | train_accuracy: 0.79852 | valid_accuracy: 0.78307 |  0:33:24s\n",
      "epoch 82 | loss: 0.53749 | train_accuracy: 0.79552 | valid_accuracy: 0.781   |  0:33:49s\n",
      "epoch 83 | loss: 0.53491 | train_accuracy: 0.79875 | valid_accuracy: 0.78324 |  0:34:13s\n",
      "epoch 84 | loss: 0.5366  | train_accuracy: 0.79901 | valid_accuracy: 0.78255 |  0:34:37s\n",
      "epoch 85 | loss: 0.53339 | train_accuracy: 0.79738 | valid_accuracy: 0.78229 |  0:35:01s\n",
      "epoch 86 | loss: 0.5334  | train_accuracy: 0.79733 | valid_accuracy: 0.7841  |  0:35:26s\n",
      "epoch 87 | loss: 0.53596 | train_accuracy: 0.79927 | valid_accuracy: 0.78212 |  0:35:50s\n",
      "epoch 88 | loss: 0.5333  | train_accuracy: 0.79882 | valid_accuracy: 0.78255 |  0:36:15s\n",
      "epoch 89 | loss: 0.53114 | train_accuracy: 0.79882 | valid_accuracy: 0.78212 |  0:36:39s\n",
      "epoch 90 | loss: 0.53273 | train_accuracy: 0.80185 | valid_accuracy: 0.78203 |  0:37:03s\n",
      "epoch 91 | loss: 0.53482 | train_accuracy: 0.7997  | valid_accuracy: 0.78418 |  0:37:27s\n",
      "epoch 92 | loss: 0.53386 | train_accuracy: 0.8011  | valid_accuracy: 0.78384 |  0:37:52s\n",
      "epoch 93 | loss: 0.53176 | train_accuracy: 0.80009 | valid_accuracy: 0.78005 |  0:38:16s\n",
      "epoch 94 | loss: 0.53222 | train_accuracy: 0.80465 | valid_accuracy: 0.78556 |  0:38:40s\n",
      "epoch 95 | loss: 0.53257 | train_accuracy: 0.79987 | valid_accuracy: 0.78203 |  0:39:04s\n",
      "epoch 96 | loss: 0.53149 | train_accuracy: 0.80084 | valid_accuracy: 0.78195 |  0:39:29s\n",
      "epoch 97 | loss: 0.53475 | train_accuracy: 0.80146 | valid_accuracy: 0.78367 |  0:39:53s\n",
      "epoch 98 | loss: 0.52747 | train_accuracy: 0.80191 | valid_accuracy: 0.7847  |  0:40:17s\n",
      "epoch 99 | loss: 0.53138 | train_accuracy: 0.80228 | valid_accuracy: 0.78436 |  0:40:42s\n",
      "epoch 100| loss: 0.52906 | train_accuracy: 0.80514 | valid_accuracy: 0.7847  |  0:41:06s\n",
      "epoch 101| loss: 0.53084 | train_accuracy: 0.8025  | valid_accuracy: 0.78556 |  0:41:30s\n",
      "epoch 102| loss: 0.53004 | train_accuracy: 0.80306 | valid_accuracy: 0.78599 |  0:41:55s\n",
      "epoch 103| loss: 0.52739 | train_accuracy: 0.80344 | valid_accuracy: 0.78401 |  0:42:19s\n",
      "epoch 104| loss: 0.52802 | train_accuracy: 0.80501 | valid_accuracy: 0.7878  |  0:42:43s\n",
      "epoch 105| loss: 0.5265  | train_accuracy: 0.80417 | valid_accuracy: 0.78814 |  0:43:08s\n",
      "epoch 106| loss: 0.52984 | train_accuracy: 0.80486 | valid_accuracy: 0.78642 |  0:43:32s\n",
      "epoch 107| loss: 0.52764 | train_accuracy: 0.80295 | valid_accuracy: 0.78358 |  0:43:56s\n",
      "epoch 108| loss: 0.5274  | train_accuracy: 0.80232 | valid_accuracy: 0.78418 |  0:44:21s\n",
      "epoch 109| loss: 0.52943 | train_accuracy: 0.8046  | valid_accuracy: 0.78479 |  0:44:44s\n",
      "epoch 110| loss: 0.52438 | train_accuracy: 0.8028  | valid_accuracy: 0.7872  |  0:45:09s\n",
      "epoch 111| loss: 0.52436 | train_accuracy: 0.80454 | valid_accuracy: 0.78745 |  0:45:33s\n",
      "epoch 112| loss: 0.52948 | train_accuracy: 0.8048  | valid_accuracy: 0.78659 |  0:45:57s\n",
      "epoch 113| loss: 0.52259 | train_accuracy: 0.80531 | valid_accuracy: 0.78711 |  0:46:21s\n",
      "epoch 114| loss: 0.52758 | train_accuracy: 0.8068  | valid_accuracy: 0.78823 |  0:46:45s\n",
      "epoch 115| loss: 0.52606 | train_accuracy: 0.80443 | valid_accuracy: 0.78806 |  0:47:10s\n",
      "epoch 116| loss: 0.52307 | train_accuracy: 0.80553 | valid_accuracy: 0.7878  |  0:47:34s\n",
      "epoch 117| loss: 0.52706 | train_accuracy: 0.80886 | valid_accuracy: 0.79055 |  0:47:58s\n",
      "epoch 118| loss: 0.52287 | train_accuracy: 0.8059  | valid_accuracy: 0.78737 |  0:48:22s\n",
      "epoch 119| loss: 0.52459 | train_accuracy: 0.8051  | valid_accuracy: 0.78582 |  0:48:46s\n",
      "epoch 120| loss: 0.52285 | train_accuracy: 0.80654 | valid_accuracy: 0.78961 |  0:49:10s\n",
      "epoch 121| loss: 0.52268 | train_accuracy: 0.80549 | valid_accuracy: 0.78935 |  0:49:34s\n",
      "epoch 122| loss: 0.51931 | train_accuracy: 0.80628 | valid_accuracy: 0.79072 |  0:49:58s\n",
      "epoch 123| loss: 0.52211 | train_accuracy: 0.80652 | valid_accuracy: 0.79098 |  0:50:22s\n",
      "epoch 124| loss: 0.52408 | train_accuracy: 0.806   | valid_accuracy: 0.79064 |  0:50:46s\n",
      "epoch 125| loss: 0.52362 | train_accuracy: 0.80818 | valid_accuracy: 0.7915  |  0:51:10s\n",
      "epoch 126| loss: 0.52329 | train_accuracy: 0.80863 | valid_accuracy: 0.79236 |  0:51:35s\n",
      "epoch 127| loss: 0.51885 | train_accuracy: 0.80914 | valid_accuracy: 0.78986 |  0:51:59s\n",
      "epoch 128| loss: 0.52003 | train_accuracy: 0.8079  | valid_accuracy: 0.78978 |  0:52:23s\n",
      "epoch 129| loss: 0.52215 | train_accuracy: 0.80938 | valid_accuracy: 0.79158 |  0:52:47s\n",
      "epoch 130| loss: 0.52239 | train_accuracy: 0.80828 | valid_accuracy: 0.78866 |  0:53:12s\n",
      "epoch 131| loss: 0.52179 | train_accuracy: 0.80757 | valid_accuracy: 0.79055 |  0:53:36s\n",
      "epoch 132| loss: 0.52243 | train_accuracy: 0.80944 | valid_accuracy: 0.79038 |  0:54:00s\n",
      "epoch 133| loss: 0.5197  | train_accuracy: 0.80805 | valid_accuracy: 0.78866 |  0:54:25s\n",
      "epoch 134| loss: 0.5175  | train_accuracy: 0.80856 | valid_accuracy: 0.79253 |  0:54:49s\n",
      "epoch 135| loss: 0.51942 | train_accuracy: 0.8094  | valid_accuracy: 0.79021 |  0:55:13s\n",
      "epoch 136| loss: 0.52136 | train_accuracy: 0.81132 | valid_accuracy: 0.79571 |  0:55:37s\n",
      "epoch 137| loss: 0.51618 | train_accuracy: 0.80998 | valid_accuracy: 0.79236 |  0:56:02s\n",
      "epoch 138| loss: 0.51788 | train_accuracy: 0.80968 | valid_accuracy: 0.79494 |  0:56:26s\n",
      "epoch 139| loss: 0.51849 | train_accuracy: 0.80854 | valid_accuracy: 0.79236 |  0:56:50s\n",
      "epoch 140| loss: 0.51381 | train_accuracy: 0.80762 | valid_accuracy: 0.79193 |  0:57:15s\n",
      "epoch 141| loss: 0.51861 | train_accuracy: 0.8079  | valid_accuracy: 0.7927  |  0:57:39s\n",
      "epoch 142| loss: 0.51678 | train_accuracy: 0.80968 | valid_accuracy: 0.79176 |  0:58:03s\n",
      "epoch 143| loss: 0.51621 | train_accuracy: 0.8091  | valid_accuracy: 0.79382 |  0:58:27s\n",
      "epoch 144| loss: 0.51513 | train_accuracy: 0.80658 | valid_accuracy: 0.79176 |  0:58:51s\n",
      "epoch 145| loss: 0.51787 | train_accuracy: 0.80904 | valid_accuracy: 0.79434 |  0:59:16s\n",
      "epoch 146| loss: 0.5146  | train_accuracy: 0.81102 | valid_accuracy: 0.79451 |  0:59:40s\n",
      "\n",
      "Early stopping occurred at epoch 146 with best_epoch = 136 and best_valid_accuracy = 0.79571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy:  0.7957146545047759\n",
      "Successfully saved model at ./tabnet_model_cov.zip\n"
     ]
    }
   ],
   "source": [
    "model_cov = run_tabnet(X_cov, y_cov)\n",
    "\n",
    "# save tabnet model\n",
    "saving_path_name = \"./tabnet_model_cov\"\n",
    "saved_filepath = model_cov.save_model(saving_path_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HELOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.971   | train_accuracy: 0.54899 | valid_accuracy: 0.57432 |  0:00:00s\n",
      "epoch 1  | loss: 0.81065 | train_accuracy: 0.56532 | valid_accuracy: 0.57658 |  0:00:01s\n",
      "epoch 2  | loss: 0.76538 | train_accuracy: 0.6098  | valid_accuracy: 0.5991  |  0:00:02s\n",
      "epoch 3  | loss: 0.72161 | train_accuracy: 0.63457 | valid_accuracy: 0.63964 |  0:00:03s\n",
      "epoch 4  | loss: 0.70833 | train_accuracy: 0.64471 | valid_accuracy: 0.63514 |  0:00:04s\n",
      "epoch 5  | loss: 0.67887 | train_accuracy: 0.6464  | valid_accuracy: 0.62387 |  0:00:05s\n",
      "epoch 6  | loss: 0.68401 | train_accuracy: 0.65878 | valid_accuracy: 0.64414 |  0:00:06s\n",
      "epoch 7  | loss: 0.66425 | train_accuracy: 0.66104 | valid_accuracy: 0.64865 |  0:00:07s\n",
      "epoch 8  | loss: 0.66057 | train_accuracy: 0.65766 | valid_accuracy: 0.6509  |  0:00:08s\n",
      "epoch 9  | loss: 0.65499 | train_accuracy: 0.6661  | valid_accuracy: 0.66216 |  0:00:09s\n",
      "epoch 10 | loss: 0.66365 | train_accuracy: 0.66723 | valid_accuracy: 0.65315 |  0:00:09s\n",
      "epoch 11 | loss: 0.64075 | train_accuracy: 0.66441 | valid_accuracy: 0.67117 |  0:00:10s\n",
      "epoch 12 | loss: 0.63635 | train_accuracy: 0.67849 | valid_accuracy: 0.67568 |  0:00:11s\n",
      "epoch 13 | loss: 0.6296  | train_accuracy: 0.68018 | valid_accuracy: 0.68694 |  0:00:12s\n",
      "epoch 14 | loss: 0.62831 | train_accuracy: 0.68131 | valid_accuracy: 0.68468 |  0:00:13s\n",
      "epoch 15 | loss: 0.61621 | train_accuracy: 0.67624 | valid_accuracy: 0.68694 |  0:00:14s\n",
      "epoch 16 | loss: 0.62739 | train_accuracy: 0.68074 | valid_accuracy: 0.68468 |  0:00:15s\n",
      "epoch 17 | loss: 0.61787 | train_accuracy: 0.68243 | valid_accuracy: 0.67793 |  0:00:16s\n",
      "epoch 18 | loss: 0.61214 | train_accuracy: 0.6875  | valid_accuracy: 0.68694 |  0:00:17s\n",
      "epoch 19 | loss: 0.62075 | train_accuracy: 0.68074 | valid_accuracy: 0.67793 |  0:00:18s\n",
      "epoch 20 | loss: 0.61725 | train_accuracy: 0.68131 | valid_accuracy: 0.67342 |  0:00:19s\n",
      "epoch 21 | loss: 0.61702 | train_accuracy: 0.68412 | valid_accuracy: 0.69144 |  0:00:20s\n",
      "epoch 22 | loss: 0.62696 | train_accuracy: 0.69144 | valid_accuracy: 0.68243 |  0:00:21s\n",
      "epoch 23 | loss: 0.62119 | train_accuracy: 0.692   | valid_accuracy: 0.68694 |  0:00:21s\n",
      "epoch 24 | loss: 0.6087  | train_accuracy: 0.69595 | valid_accuracy: 0.69595 |  0:00:22s\n",
      "epoch 25 | loss: 0.60121 | train_accuracy: 0.69538 | valid_accuracy: 0.69369 |  0:00:23s\n",
      "epoch 26 | loss: 0.60288 | train_accuracy: 0.70101 | valid_accuracy: 0.6982  |  0:00:24s\n",
      "epoch 27 | loss: 0.60107 | train_accuracy: 0.70045 | valid_accuracy: 0.69369 |  0:00:25s\n",
      "epoch 28 | loss: 0.59948 | train_accuracy: 0.69876 | valid_accuracy: 0.68694 |  0:00:26s\n",
      "epoch 29 | loss: 0.59018 | train_accuracy: 0.7027  | valid_accuracy: 0.69595 |  0:00:27s\n",
      "epoch 30 | loss: 0.60292 | train_accuracy: 0.70495 | valid_accuracy: 0.70495 |  0:00:28s\n",
      "epoch 31 | loss: 0.59548 | train_accuracy: 0.70495 | valid_accuracy: 0.70495 |  0:00:29s\n",
      "epoch 32 | loss: 0.587   | train_accuracy: 0.71227 | valid_accuracy: 0.72072 |  0:00:30s\n",
      "epoch 33 | loss: 0.5945  | train_accuracy: 0.71059 | valid_accuracy: 0.72523 |  0:00:31s\n",
      "epoch 34 | loss: 0.59284 | train_accuracy: 0.71227 | valid_accuracy: 0.72523 |  0:00:32s\n",
      "epoch 35 | loss: 0.59889 | train_accuracy: 0.72297 | valid_accuracy: 0.72072 |  0:00:33s\n",
      "epoch 36 | loss: 0.59493 | train_accuracy: 0.71903 | valid_accuracy: 0.71622 |  0:00:34s\n",
      "epoch 37 | loss: 0.58466 | train_accuracy: 0.71959 | valid_accuracy: 0.72297 |  0:00:35s\n",
      "epoch 38 | loss: 0.59304 | train_accuracy: 0.71959 | valid_accuracy: 0.72072 |  0:00:36s\n",
      "epoch 39 | loss: 0.58379 | train_accuracy: 0.72523 | valid_accuracy: 0.72297 |  0:00:37s\n",
      "epoch 40 | loss: 0.59335 | train_accuracy: 0.72072 | valid_accuracy: 0.72973 |  0:00:38s\n",
      "epoch 41 | loss: 0.57876 | train_accuracy: 0.71959 | valid_accuracy: 0.72973 |  0:00:38s\n",
      "epoch 42 | loss: 0.58121 | train_accuracy: 0.7241  | valid_accuracy: 0.73423 |  0:00:39s\n",
      "epoch 43 | loss: 0.59735 | train_accuracy: 0.72635 | valid_accuracy: 0.72973 |  0:00:40s\n",
      "epoch 44 | loss: 0.56942 | train_accuracy: 0.72354 | valid_accuracy: 0.72973 |  0:00:41s\n",
      "epoch 45 | loss: 0.58549 | train_accuracy: 0.72579 | valid_accuracy: 0.72748 |  0:00:42s\n",
      "epoch 46 | loss: 0.58101 | train_accuracy: 0.7241  | valid_accuracy: 0.73649 |  0:00:43s\n",
      "epoch 47 | loss: 0.5748  | train_accuracy: 0.72466 | valid_accuracy: 0.73198 |  0:00:44s\n",
      "epoch 48 | loss: 0.58398 | train_accuracy: 0.72523 | valid_accuracy: 0.73198 |  0:00:45s\n",
      "epoch 49 | loss: 0.57567 | train_accuracy: 0.72748 | valid_accuracy: 0.72973 |  0:00:46s\n",
      "epoch 50 | loss: 0.57547 | train_accuracy: 0.7286  | valid_accuracy: 0.72973 |  0:00:47s\n",
      "epoch 51 | loss: 0.56744 | train_accuracy: 0.73198 | valid_accuracy: 0.72973 |  0:00:48s\n",
      "epoch 52 | loss: 0.58149 | train_accuracy: 0.73367 | valid_accuracy: 0.72973 |  0:00:49s\n",
      "epoch 53 | loss: 0.57538 | train_accuracy: 0.73142 | valid_accuracy: 0.72748 |  0:00:50s\n",
      "epoch 54 | loss: 0.57561 | train_accuracy: 0.72804 | valid_accuracy: 0.73874 |  0:00:51s\n",
      "epoch 55 | loss: 0.57408 | train_accuracy: 0.73029 | valid_accuracy: 0.73198 |  0:00:52s\n",
      "epoch 56 | loss: 0.57856 | train_accuracy: 0.72804 | valid_accuracy: 0.72973 |  0:00:52s\n",
      "epoch 57 | loss: 0.57987 | train_accuracy: 0.72917 | valid_accuracy: 0.72748 |  0:00:53s\n",
      "epoch 58 | loss: 0.5871  | train_accuracy: 0.73029 | valid_accuracy: 0.72297 |  0:00:54s\n",
      "epoch 59 | loss: 0.57167 | train_accuracy: 0.72579 | valid_accuracy: 0.72297 |  0:00:55s\n",
      "epoch 60 | loss: 0.57449 | train_accuracy: 0.73029 | valid_accuracy: 0.72297 |  0:00:56s\n",
      "epoch 61 | loss: 0.57479 | train_accuracy: 0.72804 | valid_accuracy: 0.73423 |  0:00:57s\n",
      "epoch 62 | loss: 0.55861 | train_accuracy: 0.72804 | valid_accuracy: 0.73423 |  0:00:58s\n",
      "epoch 63 | loss: 0.57201 | train_accuracy: 0.72804 | valid_accuracy: 0.74099 |  0:00:59s\n",
      "epoch 64 | loss: 0.56807 | train_accuracy: 0.73029 | valid_accuracy: 0.74099 |  0:01:00s\n",
      "epoch 65 | loss: 0.57138 | train_accuracy: 0.73255 | valid_accuracy: 0.73649 |  0:01:01s\n",
      "epoch 66 | loss: 0.57222 | train_accuracy: 0.72748 | valid_accuracy: 0.73874 |  0:01:02s\n",
      "epoch 67 | loss: 0.57104 | train_accuracy: 0.72973 | valid_accuracy: 0.74099 |  0:01:03s\n",
      "epoch 68 | loss: 0.56684 | train_accuracy: 0.73142 | valid_accuracy: 0.73649 |  0:01:04s\n",
      "epoch 69 | loss: 0.57005 | train_accuracy: 0.73367 | valid_accuracy: 0.73649 |  0:01:05s\n",
      "epoch 70 | loss: 0.56788 | train_accuracy: 0.7348  | valid_accuracy: 0.73198 |  0:01:06s\n",
      "epoch 71 | loss: 0.57037 | train_accuracy: 0.73536 | valid_accuracy: 0.73423 |  0:01:06s\n",
      "epoch 72 | loss: 0.57223 | train_accuracy: 0.73592 | valid_accuracy: 0.72523 |  0:01:07s\n",
      "epoch 73 | loss: 0.55763 | train_accuracy: 0.73874 | valid_accuracy: 0.73198 |  0:01:08s\n",
      "\n",
      "Early stopping occurred at epoch 73 with best_epoch = 63 and best_valid_accuracy = 0.74099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.96368 | train_accuracy: 0.51633 | valid_accuracy: 0.4955  |  0:00:00s\n",
      "epoch 1  | loss: 0.82052 | train_accuracy: 0.56813 | valid_accuracy: 0.58333 |  0:00:01s\n",
      "epoch 2  | loss: 0.74492 | train_accuracy: 0.61486 | valid_accuracy: 0.62838 |  0:00:02s\n",
      "epoch 3  | loss: 0.71466 | train_accuracy: 0.63964 | valid_accuracy: 0.61486 |  0:00:03s\n",
      "epoch 4  | loss: 0.69147 | train_accuracy: 0.64077 | valid_accuracy: 0.61261 |  0:00:04s\n",
      "epoch 5  | loss: 0.67569 | train_accuracy: 0.65653 | valid_accuracy: 0.61712 |  0:00:05s\n",
      "epoch 6  | loss: 0.65684 | train_accuracy: 0.65991 | valid_accuracy: 0.64414 |  0:00:06s\n",
      "epoch 7  | loss: 0.6636  | train_accuracy: 0.66667 | valid_accuracy: 0.65315 |  0:00:07s\n",
      "epoch 8  | loss: 0.6366  | train_accuracy: 0.67005 | valid_accuracy: 0.65541 |  0:00:08s\n",
      "epoch 9  | loss: 0.65327 | train_accuracy: 0.67962 | valid_accuracy: 0.65541 |  0:00:09s\n",
      "epoch 10 | loss: 0.63797 | train_accuracy: 0.67793 | valid_accuracy: 0.65991 |  0:00:10s\n",
      "epoch 11 | loss: 0.62498 | train_accuracy: 0.69088 | valid_accuracy: 0.66667 |  0:00:11s\n",
      "epoch 12 | loss: 0.61418 | train_accuracy: 0.69313 | valid_accuracy: 0.66441 |  0:00:12s\n",
      "epoch 13 | loss: 0.63428 | train_accuracy: 0.69144 | valid_accuracy: 0.66216 |  0:00:13s\n",
      "epoch 14 | loss: 0.6176  | train_accuracy: 0.69313 | valid_accuracy: 0.66892 |  0:00:14s\n",
      "epoch 15 | loss: 0.62959 | train_accuracy: 0.7027  | valid_accuracy: 0.65541 |  0:00:14s\n",
      "epoch 16 | loss: 0.60909 | train_accuracy: 0.70101 | valid_accuracy: 0.68468 |  0:00:15s\n",
      "epoch 17 | loss: 0.61604 | train_accuracy: 0.6982  | valid_accuracy: 0.68468 |  0:00:16s\n",
      "epoch 18 | loss: 0.6127  | train_accuracy: 0.70327 | valid_accuracy: 0.68694 |  0:00:17s\n",
      "epoch 19 | loss: 0.60846 | train_accuracy: 0.70214 | valid_accuracy: 0.6982  |  0:00:18s\n",
      "epoch 20 | loss: 0.59513 | train_accuracy: 0.7089  | valid_accuracy: 0.68468 |  0:00:19s\n",
      "epoch 21 | loss: 0.60415 | train_accuracy: 0.70833 | valid_accuracy: 0.68468 |  0:00:20s\n",
      "epoch 22 | loss: 0.59084 | train_accuracy: 0.71396 | valid_accuracy: 0.67793 |  0:00:21s\n",
      "epoch 23 | loss: 0.59368 | train_accuracy: 0.72128 | valid_accuracy: 0.68468 |  0:00:22s\n",
      "epoch 24 | loss: 0.58797 | train_accuracy: 0.71959 | valid_accuracy: 0.68468 |  0:00:23s\n",
      "epoch 25 | loss: 0.59915 | train_accuracy: 0.71734 | valid_accuracy: 0.68468 |  0:00:24s\n",
      "epoch 26 | loss: 0.59385 | train_accuracy: 0.71847 | valid_accuracy: 0.68243 |  0:00:25s\n",
      "epoch 27 | loss: 0.59213 | train_accuracy: 0.7241  | valid_accuracy: 0.69369 |  0:00:25s\n",
      "epoch 28 | loss: 0.58459 | train_accuracy: 0.73029 | valid_accuracy: 0.68243 |  0:00:26s\n",
      "epoch 29 | loss: 0.57452 | train_accuracy: 0.73423 | valid_accuracy: 0.67568 |  0:00:27s\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_valid_accuracy = 0.6982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.92614 | train_accuracy: 0.53435 | valid_accuracy: 0.53378 |  0:00:00s\n",
      "epoch 1  | loss: 0.8067  | train_accuracy: 0.57658 | valid_accuracy: 0.54054 |  0:00:01s\n",
      "epoch 2  | loss: 0.76668 | train_accuracy: 0.61374 | valid_accuracy: 0.5991  |  0:00:02s\n",
      "epoch 3  | loss: 0.72056 | train_accuracy: 0.62275 | valid_accuracy: 0.63514 |  0:00:03s\n",
      "epoch 4  | loss: 0.68109 | train_accuracy: 0.63514 | valid_accuracy: 0.6464  |  0:00:04s\n",
      "epoch 5  | loss: 0.68852 | train_accuracy: 0.6357  | valid_accuracy: 0.6464  |  0:00:05s\n",
      "epoch 6  | loss: 0.67709 | train_accuracy: 0.63908 | valid_accuracy: 0.63288 |  0:00:06s\n",
      "epoch 7  | loss: 0.66688 | train_accuracy: 0.6402  | valid_accuracy: 0.64189 |  0:00:07s\n",
      "epoch 8  | loss: 0.65525 | train_accuracy: 0.65034 | valid_accuracy: 0.6464  |  0:00:08s\n",
      "epoch 9  | loss: 0.65904 | train_accuracy: 0.65766 | valid_accuracy: 0.65991 |  0:00:09s\n",
      "epoch 10 | loss: 0.65628 | train_accuracy: 0.65484 | valid_accuracy: 0.66667 |  0:00:10s\n",
      "epoch 11 | loss: 0.63673 | train_accuracy: 0.65935 | valid_accuracy: 0.65991 |  0:00:11s\n",
      "epoch 12 | loss: 0.64813 | train_accuracy: 0.66216 | valid_accuracy: 0.67342 |  0:00:12s\n",
      "epoch 13 | loss: 0.63839 | train_accuracy: 0.6616  | valid_accuracy: 0.67342 |  0:00:13s\n",
      "epoch 14 | loss: 0.61841 | train_accuracy: 0.6661  | valid_accuracy: 0.69144 |  0:00:14s\n",
      "epoch 15 | loss: 0.6266  | train_accuracy: 0.67399 | valid_accuracy: 0.67568 |  0:00:15s\n",
      "epoch 16 | loss: 0.6266  | train_accuracy: 0.67005 | valid_accuracy: 0.67342 |  0:00:16s\n",
      "epoch 17 | loss: 0.62547 | train_accuracy: 0.67342 | valid_accuracy: 0.67117 |  0:00:17s\n",
      "epoch 18 | loss: 0.62114 | train_accuracy: 0.68018 | valid_accuracy: 0.68243 |  0:00:18s\n",
      "epoch 19 | loss: 0.62904 | train_accuracy: 0.68131 | valid_accuracy: 0.68243 |  0:00:19s\n",
      "epoch 20 | loss: 0.61812 | train_accuracy: 0.692   | valid_accuracy: 0.68243 |  0:00:19s\n",
      "epoch 21 | loss: 0.61817 | train_accuracy: 0.69088 | valid_accuracy: 0.69369 |  0:00:20s\n",
      "epoch 22 | loss: 0.61628 | train_accuracy: 0.68919 | valid_accuracy: 0.70721 |  0:00:21s\n",
      "epoch 23 | loss: 0.6011  | train_accuracy: 0.69313 | valid_accuracy: 0.70045 |  0:00:22s\n",
      "epoch 24 | loss: 0.60853 | train_accuracy: 0.69932 | valid_accuracy: 0.68694 |  0:00:23s\n",
      "epoch 25 | loss: 0.61258 | train_accuracy: 0.70327 | valid_accuracy: 0.6982  |  0:00:24s\n",
      "epoch 26 | loss: 0.61024 | train_accuracy: 0.70777 | valid_accuracy: 0.71847 |  0:00:25s\n",
      "epoch 27 | loss: 0.59159 | train_accuracy: 0.71002 | valid_accuracy: 0.70946 |  0:00:26s\n",
      "epoch 28 | loss: 0.60707 | train_accuracy: 0.7089  | valid_accuracy: 0.70495 |  0:00:27s\n",
      "epoch 29 | loss: 0.5978  | train_accuracy: 0.71002 | valid_accuracy: 0.70946 |  0:00:28s\n",
      "epoch 30 | loss: 0.60711 | train_accuracy: 0.7089  | valid_accuracy: 0.71847 |  0:00:29s\n",
      "epoch 31 | loss: 0.60055 | train_accuracy: 0.71115 | valid_accuracy: 0.71396 |  0:00:29s\n",
      "epoch 32 | loss: 0.60548 | train_accuracy: 0.71509 | valid_accuracy: 0.72297 |  0:00:30s\n",
      "epoch 33 | loss: 0.57396 | train_accuracy: 0.71565 | valid_accuracy: 0.71171 |  0:00:31s\n",
      "epoch 34 | loss: 0.5933  | train_accuracy: 0.71453 | valid_accuracy: 0.71171 |  0:00:32s\n",
      "epoch 35 | loss: 0.58273 | train_accuracy: 0.72072 | valid_accuracy: 0.71171 |  0:00:33s\n",
      "epoch 36 | loss: 0.58574 | train_accuracy: 0.72241 | valid_accuracy: 0.71171 |  0:00:34s\n",
      "epoch 37 | loss: 0.58153 | train_accuracy: 0.72635 | valid_accuracy: 0.71622 |  0:00:35s\n",
      "epoch 38 | loss: 0.5833  | train_accuracy: 0.72973 | valid_accuracy: 0.72072 |  0:00:36s\n",
      "epoch 39 | loss: 0.5817  | train_accuracy: 0.71959 | valid_accuracy: 0.71171 |  0:00:37s\n",
      "epoch 40 | loss: 0.59588 | train_accuracy: 0.72072 | valid_accuracy: 0.70946 |  0:00:38s\n",
      "epoch 41 | loss: 0.58746 | train_accuracy: 0.72072 | valid_accuracy: 0.7027  |  0:00:39s\n",
      "epoch 42 | loss: 0.58367 | train_accuracy: 0.71791 | valid_accuracy: 0.71171 |  0:00:39s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_valid_accuracy = 0.72297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.92682 | train_accuracy: 0.5366  | valid_accuracy: 0.53604 |  0:00:00s\n",
      "epoch 1  | loss: 0.83566 | train_accuracy: 0.56588 | valid_accuracy: 0.54279 |  0:00:01s\n",
      "epoch 2  | loss: 0.72163 | train_accuracy: 0.61543 | valid_accuracy: 0.58108 |  0:00:02s\n",
      "epoch 3  | loss: 0.7324  | train_accuracy: 0.64752 | valid_accuracy: 0.61712 |  0:00:03s\n",
      "epoch 4  | loss: 0.68891 | train_accuracy: 0.65146 | valid_accuracy: 0.64414 |  0:00:04s\n",
      "epoch 5  | loss: 0.69031 | train_accuracy: 0.66216 | valid_accuracy: 0.64189 |  0:00:05s\n",
      "epoch 6  | loss: 0.67634 | train_accuracy: 0.66667 | valid_accuracy: 0.62613 |  0:00:06s\n",
      "epoch 7  | loss: 0.65824 | train_accuracy: 0.6661  | valid_accuracy: 0.63288 |  0:00:07s\n",
      "epoch 8  | loss: 0.64853 | train_accuracy: 0.6723  | valid_accuracy: 0.61036 |  0:00:08s\n",
      "epoch 9  | loss: 0.63562 | train_accuracy: 0.67624 | valid_accuracy: 0.63739 |  0:00:09s\n",
      "epoch 10 | loss: 0.62354 | train_accuracy: 0.67849 | valid_accuracy: 0.64189 |  0:00:10s\n",
      "epoch 11 | loss: 0.6132  | train_accuracy: 0.68018 | valid_accuracy: 0.64414 |  0:00:10s\n",
      "epoch 12 | loss: 0.62762 | train_accuracy: 0.68581 | valid_accuracy: 0.63739 |  0:00:11s\n",
      "epoch 13 | loss: 0.62125 | train_accuracy: 0.69088 | valid_accuracy: 0.6464  |  0:00:12s\n",
      "epoch 14 | loss: 0.60578 | train_accuracy: 0.69144 | valid_accuracy: 0.64865 |  0:00:13s\n",
      "epoch 15 | loss: 0.60757 | train_accuracy: 0.68975 | valid_accuracy: 0.64865 |  0:00:14s\n",
      "epoch 16 | loss: 0.60711 | train_accuracy: 0.692   | valid_accuracy: 0.65315 |  0:00:15s\n",
      "epoch 17 | loss: 0.60048 | train_accuracy: 0.69764 | valid_accuracy: 0.64414 |  0:00:16s\n",
      "epoch 18 | loss: 0.59479 | train_accuracy: 0.70383 | valid_accuracy: 0.64414 |  0:00:17s\n",
      "epoch 19 | loss: 0.59201 | train_accuracy: 0.70721 | valid_accuracy: 0.64865 |  0:00:18s\n",
      "epoch 20 | loss: 0.59822 | train_accuracy: 0.70045 | valid_accuracy: 0.66892 |  0:00:19s\n",
      "epoch 21 | loss: 0.59763 | train_accuracy: 0.7027  | valid_accuracy: 0.68243 |  0:00:20s\n",
      "epoch 22 | loss: 0.59331 | train_accuracy: 0.70777 | valid_accuracy: 0.66667 |  0:00:21s\n",
      "epoch 23 | loss: 0.57584 | train_accuracy: 0.71396 | valid_accuracy: 0.65991 |  0:00:21s\n",
      "epoch 24 | loss: 0.59797 | train_accuracy: 0.70833 | valid_accuracy: 0.66892 |  0:00:22s\n",
      "epoch 25 | loss: 0.59124 | train_accuracy: 0.70946 | valid_accuracy: 0.66892 |  0:00:23s\n",
      "epoch 26 | loss: 0.57179 | train_accuracy: 0.70833 | valid_accuracy: 0.67793 |  0:00:24s\n",
      "epoch 27 | loss: 0.59512 | train_accuracy: 0.71734 | valid_accuracy: 0.66667 |  0:00:25s\n",
      "epoch 28 | loss: 0.58595 | train_accuracy: 0.71847 | valid_accuracy: 0.68018 |  0:00:26s\n",
      "epoch 29 | loss: 0.58903 | train_accuracy: 0.72016 | valid_accuracy: 0.67568 |  0:00:27s\n",
      "epoch 30 | loss: 0.57629 | train_accuracy: 0.72635 | valid_accuracy: 0.67793 |  0:00:28s\n",
      "epoch 31 | loss: 0.57519 | train_accuracy: 0.7286  | valid_accuracy: 0.68018 |  0:00:29s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_valid_accuracy = 0.68243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.95767 | train_accuracy: 0.52365 | valid_accuracy: 0.49099 |  0:00:00s\n",
      "epoch 1  | loss: 0.79685 | train_accuracy: 0.54955 | valid_accuracy: 0.55405 |  0:00:01s\n",
      "epoch 2  | loss: 0.75958 | train_accuracy: 0.61543 | valid_accuracy: 0.60811 |  0:00:02s\n",
      "epoch 3  | loss: 0.70544 | train_accuracy: 0.63626 | valid_accuracy: 0.62838 |  0:00:03s\n",
      "epoch 4  | loss: 0.68738 | train_accuracy: 0.6402  | valid_accuracy: 0.61486 |  0:00:04s\n",
      "epoch 5  | loss: 0.67496 | train_accuracy: 0.64358 | valid_accuracy: 0.61486 |  0:00:05s\n",
      "epoch 6  | loss: 0.66763 | train_accuracy: 0.65259 | valid_accuracy: 0.62613 |  0:00:06s\n",
      "epoch 7  | loss: 0.66721 | train_accuracy: 0.65259 | valid_accuracy: 0.62387 |  0:00:07s\n",
      "epoch 8  | loss: 0.65911 | train_accuracy: 0.65541 | valid_accuracy: 0.6464  |  0:00:08s\n",
      "epoch 9  | loss: 0.66316 | train_accuracy: 0.66385 | valid_accuracy: 0.64865 |  0:00:09s\n",
      "epoch 10 | loss: 0.64286 | train_accuracy: 0.67117 | valid_accuracy: 0.63739 |  0:00:10s\n",
      "epoch 11 | loss: 0.63078 | train_accuracy: 0.67117 | valid_accuracy: 0.6464  |  0:00:11s\n",
      "epoch 12 | loss: 0.63758 | train_accuracy: 0.68187 | valid_accuracy: 0.65315 |  0:00:12s\n",
      "epoch 13 | loss: 0.63102 | train_accuracy: 0.67962 | valid_accuracy: 0.64414 |  0:00:13s\n",
      "epoch 14 | loss: 0.62709 | train_accuracy: 0.68187 | valid_accuracy: 0.67342 |  0:00:13s\n",
      "epoch 15 | loss: 0.64995 | train_accuracy: 0.68637 | valid_accuracy: 0.67342 |  0:00:14s\n",
      "epoch 16 | loss: 0.62156 | train_accuracy: 0.692   | valid_accuracy: 0.66892 |  0:00:15s\n",
      "epoch 17 | loss: 0.61118 | train_accuracy: 0.69651 | valid_accuracy: 0.66441 |  0:00:16s\n",
      "epoch 18 | loss: 0.61099 | train_accuracy: 0.70495 | valid_accuracy: 0.68243 |  0:00:17s\n",
      "epoch 19 | loss: 0.61659 | train_accuracy: 0.70946 | valid_accuracy: 0.69369 |  0:00:18s\n",
      "epoch 20 | loss: 0.59934 | train_accuracy: 0.71734 | valid_accuracy: 0.70495 |  0:00:19s\n",
      "epoch 21 | loss: 0.60035 | train_accuracy: 0.71171 | valid_accuracy: 0.69144 |  0:00:20s\n",
      "epoch 22 | loss: 0.61638 | train_accuracy: 0.71396 | valid_accuracy: 0.6982  |  0:00:21s\n",
      "epoch 23 | loss: 0.60082 | train_accuracy: 0.7134  | valid_accuracy: 0.7027  |  0:00:22s\n",
      "epoch 24 | loss: 0.58805 | train_accuracy: 0.71396 | valid_accuracy: 0.69595 |  0:00:23s\n",
      "epoch 25 | loss: 0.59104 | train_accuracy: 0.71903 | valid_accuracy: 0.69369 |  0:00:24s\n",
      "epoch 26 | loss: 0.58937 | train_accuracy: 0.71678 | valid_accuracy: 0.70721 |  0:00:24s\n",
      "epoch 27 | loss: 0.60007 | train_accuracy: 0.72354 | valid_accuracy: 0.70946 |  0:00:25s\n",
      "epoch 28 | loss: 0.5877  | train_accuracy: 0.7241  | valid_accuracy: 0.71622 |  0:00:26s\n",
      "epoch 29 | loss: 0.5829  | train_accuracy: 0.72748 | valid_accuracy: 0.71171 |  0:00:27s\n",
      "epoch 30 | loss: 0.5911  | train_accuracy: 0.72579 | valid_accuracy: 0.7027  |  0:00:28s\n",
      "epoch 31 | loss: 0.57734 | train_accuracy: 0.72241 | valid_accuracy: 0.69595 |  0:00:29s\n",
      "epoch 32 | loss: 0.58288 | train_accuracy: 0.72523 | valid_accuracy: 0.69595 |  0:00:30s\n",
      "epoch 33 | loss: 0.57914 | train_accuracy: 0.73029 | valid_accuracy: 0.70946 |  0:00:31s\n",
      "epoch 34 | loss: 0.58467 | train_accuracy: 0.72973 | valid_accuracy: 0.70721 |  0:00:32s\n",
      "epoch 35 | loss: 0.5703  | train_accuracy: 0.73198 | valid_accuracy: 0.70721 |  0:00:33s\n",
      "epoch 36 | loss: 0.55952 | train_accuracy: 0.73142 | valid_accuracy: 0.70946 |  0:00:34s\n",
      "epoch 37 | loss: 0.56744 | train_accuracy: 0.73367 | valid_accuracy: 0.70721 |  0:00:35s\n",
      "epoch 38 | loss: 0.57427 | train_accuracy: 0.73423 | valid_accuracy: 0.70946 |  0:00:35s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_valid_accuracy = 0.71622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy:  0.7121621621621622\n",
      "Successfully saved model at ./tabnet_model_heloc.zip\n"
     ]
    }
   ],
   "source": [
    "model_heloc = run_tabnet(X_heloc, y_heloc)\n",
    "\n",
    "# save tabnet model\n",
    "saving_path_name = \"./tabnet_model_heloc\"\n",
    "saved_filepath = model_heloc.save_model(saving_path_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIGGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.63092 | train_accuracy: 0.74628 | valid_accuracy: 0.74202 |  0:00:19s\n",
      "epoch 1  | loss: 0.50916 | train_accuracy: 0.79643 | valid_accuracy: 0.79698 |  0:00:38s\n",
      "epoch 2  | loss: 0.4532  | train_accuracy: 0.81271 | valid_accuracy: 0.81154 |  0:00:57s\n",
      "epoch 3  | loss: 0.43311 | train_accuracy: 0.82164 | valid_accuracy: 0.8219  |  0:01:16s\n",
      "epoch 4  | loss: 0.42596 | train_accuracy: 0.82488 | valid_accuracy: 0.82421 |  0:01:37s\n",
      "epoch 5  | loss: 0.42206 | train_accuracy: 0.82486 | valid_accuracy: 0.82243 |  0:01:56s\n",
      "epoch 6  | loss: 0.41766 | train_accuracy: 0.82863 | valid_accuracy: 0.82756 |  0:02:16s\n",
      "epoch 7  | loss: 0.41081 | train_accuracy: 0.82559 | valid_accuracy: 0.82525 |  0:02:35s\n",
      "epoch 8  | loss: 0.40983 | train_accuracy: 0.82651 | valid_accuracy: 0.82515 |  0:02:55s\n",
      "epoch 9  | loss: 0.40519 | train_accuracy: 0.82677 | valid_accuracy: 0.82285 |  0:03:14s\n",
      "epoch 10 | loss: 0.40438 | train_accuracy: 0.83637 | valid_accuracy: 0.83541 |  0:03:33s\n",
      "epoch 11 | loss: 0.39871 | train_accuracy: 0.83182 | valid_accuracy: 0.82965 |  0:03:52s\n",
      "epoch 12 | loss: 0.40145 | train_accuracy: 0.83554 | valid_accuracy: 0.83321 |  0:04:12s\n",
      "epoch 13 | loss: 0.39797 | train_accuracy: 0.83425 | valid_accuracy: 0.83154 |  0:04:31s\n",
      "epoch 14 | loss: 0.3971  | train_accuracy: 0.83279 | valid_accuracy: 0.83216 |  0:04:50s\n",
      "epoch 15 | loss: 0.39576 | train_accuracy: 0.83412 | valid_accuracy: 0.8329  |  0:05:10s\n",
      "epoch 16 | loss: 0.39457 | train_accuracy: 0.83082 | valid_accuracy: 0.82892 |  0:05:29s\n",
      "epoch 17 | loss: 0.39353 | train_accuracy: 0.83407 | valid_accuracy: 0.83164 |  0:05:48s\n",
      "epoch 18 | loss: 0.39236 | train_accuracy: 0.83378 | valid_accuracy: 0.83195 |  0:06:07s\n",
      "epoch 19 | loss: 0.39195 | train_accuracy: 0.83936 | valid_accuracy: 0.83688 |  0:06:27s\n",
      "epoch 20 | loss: 0.39095 | train_accuracy: 0.83352 | valid_accuracy: 0.83028 |  0:06:46s\n",
      "epoch 21 | loss: 0.38872 | train_accuracy: 0.83321 | valid_accuracy: 0.83269 |  0:07:05s\n",
      "epoch 22 | loss: 0.38717 | train_accuracy: 0.83423 | valid_accuracy: 0.83101 |  0:07:24s\n",
      "epoch 23 | loss: 0.38704 | train_accuracy: 0.83645 | valid_accuracy: 0.83562 |  0:07:44s\n",
      "epoch 24 | loss: 0.38874 | train_accuracy: 0.8386  | valid_accuracy: 0.83729 |  0:08:03s\n",
      "epoch 25 | loss: 0.38699 | train_accuracy: 0.83857 | valid_accuracy: 0.83761 |  0:08:22s\n",
      "epoch 26 | loss: 0.38455 | train_accuracy: 0.83821 | valid_accuracy: 0.83677 |  0:08:41s\n",
      "epoch 27 | loss: 0.38375 | train_accuracy: 0.83949 | valid_accuracy: 0.83709 |  0:09:01s\n",
      "epoch 28 | loss: 0.38509 | train_accuracy: 0.83784 | valid_accuracy: 0.83813 |  0:09:20s\n",
      "epoch 29 | loss: 0.38624 | train_accuracy: 0.838   | valid_accuracy: 0.83667 |  0:09:39s\n",
      "epoch 30 | loss: 0.38354 | train_accuracy: 0.83554 | valid_accuracy: 0.83342 |  0:09:59s\n",
      "epoch 31 | loss: 0.38449 | train_accuracy: 0.84064 | valid_accuracy: 0.83981 |  0:10:18s\n",
      "epoch 32 | loss: 0.38442 | train_accuracy: 0.84027 | valid_accuracy: 0.83981 |  0:10:37s\n",
      "epoch 33 | loss: 0.38427 | train_accuracy: 0.83716 | valid_accuracy: 0.83499 |  0:10:57s\n",
      "epoch 34 | loss: 0.38399 | train_accuracy: 0.83834 | valid_accuracy: 0.83667 |  0:11:16s\n",
      "epoch 35 | loss: 0.38237 | train_accuracy: 0.8387  | valid_accuracy: 0.83646 |  0:11:35s\n",
      "epoch 36 | loss: 0.38201 | train_accuracy: 0.83836 | valid_accuracy: 0.83677 |  0:11:55s\n",
      "epoch 37 | loss: 0.38024 | train_accuracy: 0.84077 | valid_accuracy: 0.83907 |  0:12:14s\n",
      "epoch 38 | loss: 0.382   | train_accuracy: 0.84305 | valid_accuracy: 0.83918 |  0:12:33s\n",
      "epoch 39 | loss: 0.38315 | train_accuracy: 0.83944 | valid_accuracy: 0.83729 |  0:12:52s\n",
      "epoch 40 | loss: 0.38079 | train_accuracy: 0.84187 | valid_accuracy: 0.83981 |  0:13:12s\n",
      "epoch 41 | loss: 0.38083 | train_accuracy: 0.83671 | valid_accuracy: 0.83321 |  0:13:31s\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 31 and best_valid_accuracy = 0.83981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.63819 | train_accuracy: 0.70699 | valid_accuracy: 0.70286 |  0:00:19s\n",
      "epoch 1  | loss: 0.53097 | train_accuracy: 0.80486 | valid_accuracy: 0.80013 |  0:00:38s\n",
      "epoch 2  | loss: 0.45229 | train_accuracy: 0.81886 | valid_accuracy: 0.81541 |  0:00:58s\n",
      "epoch 3  | loss: 0.43191 | train_accuracy: 0.82415 | valid_accuracy: 0.82201 |  0:01:19s\n",
      "epoch 4  | loss: 0.42542 | train_accuracy: 0.82541 | valid_accuracy: 0.8196  |  0:01:40s\n",
      "epoch 5  | loss: 0.41569 | train_accuracy: 0.82831 | valid_accuracy: 0.82316 |  0:02:02s\n",
      "epoch 6  | loss: 0.41294 | train_accuracy: 0.83297 | valid_accuracy: 0.8285  |  0:02:22s\n",
      "epoch 7  | loss: 0.40707 | train_accuracy: 0.82407 | valid_accuracy: 0.81751 |  0:02:42s\n",
      "epoch 8  | loss: 0.4033  | train_accuracy: 0.82836 | valid_accuracy: 0.82326 |  0:03:02s\n",
      "epoch 9  | loss: 0.40068 | train_accuracy: 0.83274 | valid_accuracy: 0.82536 |  0:03:21s\n",
      "epoch 10 | loss: 0.39838 | train_accuracy: 0.83198 | valid_accuracy: 0.82525 |  0:03:41s\n",
      "epoch 11 | loss: 0.39616 | train_accuracy: 0.82761 | valid_accuracy: 0.81782 |  0:04:01s\n",
      "epoch 12 | loss: 0.39318 | train_accuracy: 0.83504 | valid_accuracy: 0.82463 |  0:04:21s\n",
      "epoch 13 | loss: 0.39222 | train_accuracy: 0.83075 | valid_accuracy: 0.82159 |  0:04:40s\n",
      "epoch 14 | loss: 0.3909  | train_accuracy: 0.84067 | valid_accuracy: 0.83227 |  0:05:00s\n",
      "epoch 15 | loss: 0.39302 | train_accuracy: 0.837   | valid_accuracy: 0.83143 |  0:05:20s\n",
      "epoch 16 | loss: 0.39118 | train_accuracy: 0.83274 | valid_accuracy: 0.824   |  0:05:40s\n",
      "epoch 17 | loss: 0.38749 | train_accuracy: 0.827   | valid_accuracy: 0.81562 |  0:06:00s\n",
      "epoch 18 | loss: 0.38819 | train_accuracy: 0.83093 | valid_accuracy: 0.82096 |  0:06:20s\n",
      "epoch 19 | loss: 0.38826 | train_accuracy: 0.83349 | valid_accuracy: 0.82421 |  0:06:39s\n",
      "epoch 20 | loss: 0.38745 | train_accuracy: 0.83849 | valid_accuracy: 0.83049 |  0:06:59s\n",
      "epoch 21 | loss: 0.38352 | train_accuracy: 0.83441 | valid_accuracy: 0.82567 |  0:07:19s\n",
      "epoch 22 | loss: 0.3847  | train_accuracy: 0.83365 | valid_accuracy: 0.82431 |  0:07:39s\n",
      "epoch 23 | loss: 0.38482 | train_accuracy: 0.83745 | valid_accuracy: 0.82934 |  0:07:58s\n",
      "epoch 24 | loss: 0.38485 | train_accuracy: 0.8358  | valid_accuracy: 0.82829 |  0:08:18s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_valid_accuracy = 0.83227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.62581 | train_accuracy: 0.75968 | valid_accuracy: 0.7551  |  0:00:19s\n",
      "epoch 1  | loss: 0.50691 | train_accuracy: 0.79609 | valid_accuracy: 0.79081 |  0:00:39s\n",
      "epoch 2  | loss: 0.45071 | train_accuracy: 0.81308 | valid_accuracy: 0.81007 |  0:00:59s\n",
      "epoch 3  | loss: 0.43351 | train_accuracy: 0.82164 | valid_accuracy: 0.82201 |  0:01:18s\n",
      "epoch 4  | loss: 0.42273 | train_accuracy: 0.82156 | valid_accuracy: 0.82148 |  0:01:38s\n",
      "epoch 5  | loss: 0.41865 | train_accuracy: 0.82821 | valid_accuracy: 0.82693 |  0:01:58s\n",
      "epoch 6  | loss: 0.41036 | train_accuracy: 0.82386 | valid_accuracy: 0.81981 |  0:02:18s\n",
      "epoch 7  | loss: 0.40936 | train_accuracy: 0.83119 | valid_accuracy: 0.82881 |  0:02:38s\n",
      "epoch 8  | loss: 0.40461 | train_accuracy: 0.82554 | valid_accuracy: 0.82295 |  0:02:58s\n",
      "epoch 9  | loss: 0.40461 | train_accuracy: 0.82842 | valid_accuracy: 0.82253 |  0:03:18s\n",
      "epoch 10 | loss: 0.39982 | train_accuracy: 0.83891 | valid_accuracy: 0.83531 |  0:03:37s\n",
      "epoch 11 | loss: 0.39889 | train_accuracy: 0.8358  | valid_accuracy: 0.8285  |  0:03:57s\n",
      "epoch 12 | loss: 0.39873 | train_accuracy: 0.83755 | valid_accuracy: 0.82934 |  0:04:17s\n",
      "epoch 13 | loss: 0.39511 | train_accuracy: 0.83391 | valid_accuracy: 0.82965 |  0:04:36s\n",
      "epoch 14 | loss: 0.39288 | train_accuracy: 0.83915 | valid_accuracy: 0.83154 |  0:04:56s\n",
      "epoch 15 | loss: 0.39349 | train_accuracy: 0.82847 | valid_accuracy: 0.82504 |  0:05:16s\n",
      "epoch 16 | loss: 0.39357 | train_accuracy: 0.83465 | valid_accuracy: 0.82986 |  0:05:35s\n",
      "epoch 17 | loss: 0.39014 | train_accuracy: 0.83897 | valid_accuracy: 0.83269 |  0:05:55s\n",
      "epoch 18 | loss: 0.39193 | train_accuracy: 0.8359  | valid_accuracy: 0.8307  |  0:06:15s\n",
      "epoch 19 | loss: 0.39126 | train_accuracy: 0.84056 | valid_accuracy: 0.8307  |  0:06:34s\n",
      "epoch 20 | loss: 0.39066 | train_accuracy: 0.83828 | valid_accuracy: 0.8308  |  0:06:54s\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_valid_accuracy = 0.83531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.63476 | train_accuracy: 0.73243 | valid_accuracy: 0.73249 |  0:00:19s\n",
      "epoch 1  | loss: 0.52388 | train_accuracy: 0.79936 | valid_accuracy: 0.80149 |  0:00:39s\n",
      "epoch 2  | loss: 0.46456 | train_accuracy: 0.81253 | valid_accuracy: 0.81384 |  0:00:59s\n",
      "epoch 3  | loss: 0.44287 | train_accuracy: 0.82093 | valid_accuracy: 0.82452 |  0:01:18s\n",
      "epoch 4  | loss: 0.43291 | train_accuracy: 0.82441 | valid_accuracy: 0.82808 |  0:01:38s\n",
      "epoch 5  | loss: 0.42812 | train_accuracy: 0.82606 | valid_accuracy: 0.83101 |  0:01:58s\n",
      "epoch 6  | loss: 0.41969 | train_accuracy: 0.82381 | valid_accuracy: 0.82777 |  0:02:18s\n",
      "epoch 7  | loss: 0.41351 | train_accuracy: 0.8309  | valid_accuracy: 0.83279 |  0:02:38s\n",
      "epoch 8  | loss: 0.40808 | train_accuracy: 0.8314  | valid_accuracy: 0.83143 |  0:02:58s\n",
      "epoch 9  | loss: 0.40859 | train_accuracy: 0.83145 | valid_accuracy: 0.83394 |  0:03:18s\n",
      "epoch 10 | loss: 0.40314 | train_accuracy: 0.83399 | valid_accuracy: 0.83719 |  0:03:38s\n",
      "epoch 11 | loss: 0.39949 | train_accuracy: 0.83122 | valid_accuracy: 0.83154 |  0:03:57s\n",
      "epoch 12 | loss: 0.39844 | train_accuracy: 0.83268 | valid_accuracy: 0.83499 |  0:04:17s\n",
      "epoch 13 | loss: 0.39887 | train_accuracy: 0.83648 | valid_accuracy: 0.83866 |  0:04:36s\n",
      "epoch 14 | loss: 0.39956 | train_accuracy: 0.8298  | valid_accuracy: 0.83237 |  0:04:56s\n",
      "epoch 15 | loss: 0.39703 | train_accuracy: 0.82912 | valid_accuracy: 0.83143 |  0:05:16s\n",
      "epoch 16 | loss: 0.3952  | train_accuracy: 0.83321 | valid_accuracy: 0.83468 |  0:05:35s\n",
      "epoch 17 | loss: 0.39712 | train_accuracy: 0.83046 | valid_accuracy: 0.83332 |  0:05:55s\n",
      "epoch 18 | loss: 0.39265 | train_accuracy: 0.84048 | valid_accuracy: 0.84054 |  0:06:14s\n",
      "epoch 19 | loss: 0.39188 | train_accuracy: 0.83509 | valid_accuracy: 0.83866 |  0:06:34s\n",
      "epoch 20 | loss: 0.38845 | train_accuracy: 0.83716 | valid_accuracy: 0.83541 |  0:06:53s\n",
      "epoch 21 | loss: 0.39393 | train_accuracy: 0.83784 | valid_accuracy: 0.84012 |  0:07:13s\n",
      "epoch 22 | loss: 0.39071 | train_accuracy: 0.83499 | valid_accuracy: 0.83394 |  0:07:33s\n",
      "epoch 23 | loss: 0.38909 | train_accuracy: 0.83575 | valid_accuracy: 0.83991 |  0:07:52s\n",
      "epoch 24 | loss: 0.38901 | train_accuracy: 0.83776 | valid_accuracy: 0.8374  |  0:08:12s\n",
      "epoch 25 | loss: 0.38821 | train_accuracy: 0.84161 | valid_accuracy: 0.83991 |  0:08:32s\n",
      "epoch 26 | loss: 0.38667 | train_accuracy: 0.84043 | valid_accuracy: 0.84044 |  0:08:51s\n",
      "epoch 27 | loss: 0.38639 | train_accuracy: 0.83957 | valid_accuracy: 0.84106 |  0:09:11s\n",
      "epoch 28 | loss: 0.38719 | train_accuracy: 0.83596 | valid_accuracy: 0.83729 |  0:09:31s\n",
      "epoch 29 | loss: 0.38766 | train_accuracy: 0.84046 | valid_accuracy: 0.84232 |  0:09:51s\n",
      "epoch 30 | loss: 0.38339 | train_accuracy: 0.83928 | valid_accuracy: 0.83761 |  0:10:10s\n",
      "epoch 31 | loss: 0.3837  | train_accuracy: 0.83645 | valid_accuracy: 0.83478 |  0:10:30s\n",
      "epoch 32 | loss: 0.38286 | train_accuracy: 0.83923 | valid_accuracy: 0.83939 |  0:10:49s\n",
      "epoch 33 | loss: 0.38112 | train_accuracy: 0.8375  | valid_accuracy: 0.83782 |  0:11:09s\n",
      "epoch 34 | loss: 0.38415 | train_accuracy: 0.84294 | valid_accuracy: 0.84106 |  0:11:29s\n",
      "epoch 35 | loss: 0.37999 | train_accuracy: 0.83692 | valid_accuracy: 0.83918 |  0:11:48s\n",
      "epoch 36 | loss: 0.38189 | train_accuracy: 0.84075 | valid_accuracy: 0.84148 |  0:12:08s\n",
      "epoch 37 | loss: 0.38316 | train_accuracy: 0.83999 | valid_accuracy: 0.8418  |  0:12:27s\n",
      "epoch 38 | loss: 0.38064 | train_accuracy: 0.84156 | valid_accuracy: 0.84033 |  0:12:47s\n",
      "epoch 39 | loss: 0.37932 | train_accuracy: 0.84046 | valid_accuracy: 0.84075 |  0:13:06s\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_valid_accuracy = 0.84232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.63632 | train_accuracy: 0.7267  | valid_accuracy: 0.72304 |  0:00:19s\n",
      "epoch 1  | loss: 0.53217 | train_accuracy: 0.79018 | valid_accuracy: 0.78901 |  0:00:38s\n",
      "epoch 2  | loss: 0.46675 | train_accuracy: 0.80793 | valid_accuracy: 0.80461 |  0:00:58s\n",
      "epoch 3  | loss: 0.43922 | train_accuracy: 0.81094 | valid_accuracy: 0.80607 |  0:01:17s\n",
      "epoch 4  | loss: 0.42713 | train_accuracy: 0.82175 | valid_accuracy: 0.81696 |  0:01:37s\n",
      "epoch 5  | loss: 0.42171 | train_accuracy: 0.82175 | valid_accuracy: 0.81592 |  0:01:56s\n",
      "epoch 6  | loss: 0.41526 | train_accuracy: 0.82703 | valid_accuracy: 0.81791 |  0:02:16s\n",
      "epoch 7  | loss: 0.41282 | train_accuracy: 0.81923 | valid_accuracy: 0.8155  |  0:02:35s\n",
      "epoch 8  | loss: 0.40865 | train_accuracy: 0.82667 | valid_accuracy: 0.82304 |  0:02:55s\n",
      "epoch 9  | loss: 0.40589 | train_accuracy: 0.83583 | valid_accuracy: 0.82995 |  0:03:14s\n",
      "epoch 10 | loss: 0.40477 | train_accuracy: 0.82735 | valid_accuracy: 0.82346 |  0:03:34s\n",
      "epoch 11 | loss: 0.40248 | train_accuracy: 0.82803 | valid_accuracy: 0.82408 |  0:03:53s\n",
      "epoch 12 | loss: 0.40194 | train_accuracy: 0.8302  | valid_accuracy: 0.82796 |  0:04:13s\n",
      "epoch 13 | loss: 0.40061 | train_accuracy: 0.83515 | valid_accuracy: 0.83288 |  0:04:32s\n",
      "epoch 14 | loss: 0.39367 | train_accuracy: 0.83567 | valid_accuracy: 0.83058 |  0:04:51s\n",
      "epoch 15 | loss: 0.39622 | train_accuracy: 0.83546 | valid_accuracy: 0.83068 |  0:05:11s\n",
      "epoch 16 | loss: 0.39497 | train_accuracy: 0.83358 | valid_accuracy: 0.8288  |  0:05:30s\n",
      "epoch 17 | loss: 0.39124 | train_accuracy: 0.83706 | valid_accuracy: 0.83361 |  0:05:50s\n",
      "epoch 18 | loss: 0.39177 | train_accuracy: 0.83193 | valid_accuracy: 0.82639 |  0:06:09s\n",
      "epoch 19 | loss: 0.39231 | train_accuracy: 0.83677 | valid_accuracy: 0.8333  |  0:06:29s\n",
      "epoch 20 | loss: 0.39124 | train_accuracy: 0.83934 | valid_accuracy: 0.83539 |  0:06:48s\n",
      "epoch 21 | loss: 0.39086 | train_accuracy: 0.83659 | valid_accuracy: 0.83236 |  0:07:07s\n",
      "epoch 22 | loss: 0.38975 | train_accuracy: 0.84072 | valid_accuracy: 0.83571 |  0:07:27s\n",
      "epoch 23 | loss: 0.38877 | train_accuracy: 0.8362  | valid_accuracy: 0.83131 |  0:07:47s\n",
      "epoch 24 | loss: 0.38982 | train_accuracy: 0.83769 | valid_accuracy: 0.83183 |  0:08:06s\n",
      "epoch 25 | loss: 0.3868  | train_accuracy: 0.84114 | valid_accuracy: 0.83571 |  0:08:25s\n",
      "epoch 26 | loss: 0.38856 | train_accuracy: 0.83905 | valid_accuracy: 0.8334  |  0:08:45s\n",
      "epoch 27 | loss: 0.38727 | train_accuracy: 0.84004 | valid_accuracy: 0.83435 |  0:09:06s\n",
      "epoch 28 | loss: 0.38663 | train_accuracy: 0.84284 | valid_accuracy: 0.83613 |  0:09:26s\n",
      "epoch 29 | loss: 0.38605 | train_accuracy: 0.8424  | valid_accuracy: 0.83634 |  0:09:47s\n",
      "epoch 30 | loss: 0.38446 | train_accuracy: 0.83894 | valid_accuracy: 0.83403 |  0:10:08s\n",
      "epoch 31 | loss: 0.38327 | train_accuracy: 0.83852 | valid_accuracy: 0.83288 |  0:10:27s\n",
      "epoch 32 | loss: 0.38597 | train_accuracy: 0.84316 | valid_accuracy: 0.83749 |  0:10:47s\n",
      "epoch 33 | loss: 0.38488 | train_accuracy: 0.83863 | valid_accuracy: 0.83152 |  0:11:07s\n",
      "epoch 34 | loss: 0.38338 | train_accuracy: 0.84441 | valid_accuracy: 0.83853 |  0:11:27s\n",
      "epoch 35 | loss: 0.38511 | train_accuracy: 0.8425  | valid_accuracy: 0.83466 |  0:11:46s\n",
      "epoch 36 | loss: 0.38372 | train_accuracy: 0.84033 | valid_accuracy: 0.83393 |  0:12:06s\n",
      "epoch 37 | loss: 0.38469 | train_accuracy: 0.84135 | valid_accuracy: 0.83529 |  0:12:27s\n",
      "epoch 38 | loss: 0.3821  | train_accuracy: 0.84316 | valid_accuracy: 0.83634 |  0:12:46s\n",
      "epoch 39 | loss: 0.38294 | train_accuracy: 0.83915 | valid_accuracy: 0.83309 |  0:13:07s\n",
      "epoch 40 | loss: 0.37964 | train_accuracy: 0.84248 | valid_accuracy: 0.83602 |  0:13:27s\n",
      "epoch 41 | loss: 0.38247 | train_accuracy: 0.84159 | valid_accuracy: 0.8333  |  0:13:47s\n",
      "epoch 42 | loss: 0.38124 | train_accuracy: 0.84208 | valid_accuracy: 0.83466 |  0:14:06s\n",
      "epoch 43 | loss: 0.3832  | train_accuracy: 0.84279 | valid_accuracy: 0.83644 |  0:14:26s\n",
      "epoch 44 | loss: 0.38091 | train_accuracy: 0.8419  | valid_accuracy: 0.83508 |  0:14:47s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_valid_accuracy = 0.83853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy:  0.8376471266680225\n",
      "Successfully saved model at ./tabnet_model_higgs.zip\n"
     ]
    }
   ],
   "source": [
    "model_higgs = run_tabnet(X_higgs, y_higgs)\n",
    "\n",
    "# save tabnet model\n",
    "saving_path_name = \"./tabnet_model_higgs\"\n",
    "saved_filepath = model_higgs.save_model(saving_path_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the final predictions for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the save TabNet model for the CoverType dataset\n",
    "model_cov = TabNetClassifier()\n",
    "model_cov.load_model(\"./tabnet_model_cov.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the save TabNet model for the HELOC dataset\n",
    "model_heloc = TabNetClassifier()\n",
    "model_heloc.load_model(\"./tabnet_model_heloc.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the save TabNet model for the HIGGS dataset\n",
    "model_higgs = TabNetClassifier()\n",
    "model_higgs.load_model(\"./tabnet_model_higgs.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds, final_preds_cov, final_preds_heloc, final_preds_higgs = get_final_predictions(model_cov, model_heloc, model_higgs, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "final_preds_heloc = le.fit_transform(final_preds_heloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "le2 = LabelEncoder()\n",
    "\n",
    "final_preds_higgs = le.fit_transform(final_preds_higgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = np.concatenate((final_preds_cov, final_preds_heloc, final_preds_higgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the final predictions into zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_output = pd.DataFrame(final_preds, index=range(1, 1 + len(final_preds)))\n",
    "sol_output.rename(columns={0: \"Prediction\"}, inplace=True)\n",
    "sol_output.index.name = 'ID'\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='predictions_x.csv')  \n",
    "sol_output.to_csv('out_x.zip', index=True,\n",
    "          compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_output = pd.DataFrame(final_preds_cov, index=range(1, 1 + len(final_preds_cov)))\n",
    "sol_output.rename(columns={0: \"Prediction\"}, inplace=True)\n",
    "sol_output.index.name = 'ID'\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='predictions_tab_cov_2.csv')  \n",
    "sol_output.to_csv('out_tab_cov_2.zip', index=True,\n",
    "          compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_output = pd.DataFrame(final_preds_heloc, index=range(3501, 3501 + len(final_preds_heloc)))\n",
    "sol_output.rename(columns={0: \"Prediction\"}, inplace=True)\n",
    "sol_output.index.name = 'ID'\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='predictions_x_heloc.csv')  \n",
    "sol_output.to_csv('out_x_heloc.zip', index=True,\n",
    "          compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_output = pd.DataFrame(final_preds_higgs, index=range(4547, 4547 + len(final_preds_higgs)))\n",
    "sol_output.rename(columns={0: \"Prediction\"}, inplace=True)\n",
    "sol_output.index.name = 'ID'\n",
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='predictions_x_higgs.csv')  \n",
    "sol_output.to_csv('out_x_higgs.zip', index=True,\n",
    "          compression=compression_opts)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
